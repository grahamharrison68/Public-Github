{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/03.%20Feature%20Engineering/03.%20Feature%20Engineering.ipynb\n",
    "\n",
    "https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/04.%20Model%20Training/06.%20MT%20-%20Random%20Forest.ipynb\n",
    "\n",
    "https://towardsdatascience.com/text-classification-in-python-dd95d264c802\n",
    "\n",
    "https://github.com/miguelfzafra/Latest-News-Classifier/tree/master/0.%20Latest%20News%20Classifier/04.%20Model%20Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the data\n",
    "2. Test train split\n",
    "3. use TFIFD to add in the new features\n",
    "4. Use an algorithm to make some predictions\n",
    "5. Assess the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_FOLDER : str = \"data/out/\"\n",
    "DATA_OUT_FOLDER : str = \"data/out/\"\n",
    "\n",
    "RANDOM_STATE : int = 42\n",
    "    \n",
    "SOURCE_TRAINING_DATA_FILE : str = \"Womens Clothing E-Commerce Reviews with Emotions.xlsx\"\n",
    "SOURCE_FULL_DATA_FILE : str = \"Womens Clothing E-Commerce Reviews.xlsx\"\n",
    "UTILITIES_PATH : str = r'C:\\Users\\GHarrison\\OneDrive - Lincoln College\\Python Projects\\Data Science\\Utilities'\n",
    "MODEL_FILE : str = \"ml_model.pkl\"\n",
    "VECTORIZER_FILE : str = \"vectorizer.pkl\"\n",
    "    \n",
    "TFIDF_NGRAM_RANGE : tuple = (1,2)\n",
    "TFIDF_MAX_DF : float = 1.\n",
    "TFIDF_MIN_DF : int = 10\n",
    "TFIDF_MAX_FEATURES : int = 300\n",
    "    \n",
    "NUM_FOLDS : int = 5\n",
    "SCORING :str = 'accuracy'\n",
    "RANDOM_STATE : int = 42\n",
    "VERBOSE : int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, UTILITIES_PATH)\n",
    "\n",
    "from misc_tools import load_object, save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.read_excel(f\"{DATA_IN_FOLDER}{SOURCE_TRAINING_DATA_FILE}\")\n",
    "df_reviews.dropna(inplace=True) \n",
    "df_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Positive Feedback Count</th>\n",
       "      <th>Review Polarity</th>\n",
       "      <th>Review Sentiment</th>\n",
       "      <th>Review Subjectivity</th>\n",
       "      <th>Review Length</th>\n",
       "      <th>Review Word Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Reviewer Age</th>\n",
       "      <th>Reviewer Age Category</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion Score</th>\n",
       "      <th>Division</th>\n",
       "      <th>Department</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Recommended?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.972142</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>1049</td>\n",
       "      <td>Product 1049</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.512891</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>192</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.844207</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>847</td>\n",
       "      <td>Product 847</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>488</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.668897</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>Product 1080</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>496</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.573683</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shimmer, surprisingly goes with lots</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>482</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.554208</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                          Review Title  \\\n",
       "0      1                      My favorite buy!   \n",
       "1      2                      Flattering shirt   \n",
       "2      3               Not for the very petite   \n",
       "3      4                  Cagrcoal shimmer fun   \n",
       "4      5  Shimmer, surprisingly goes with lots   \n",
       "\n",
       "                                         Review Text  Review Rating  \\\n",
       "0  I love, love, love this jumpsuit. it's fun, fl...              5   \n",
       "1  This shirt is very flattering to all due to th...              5   \n",
       "2  I love tracy reese dresses, but this one is no...              2   \n",
       "3  I aded this in my basket at hte last mintue to...              5   \n",
       "4  I ordered this in carbon for store pick up, an...              4   \n",
       "\n",
       "   Review Positive Feedback Count  Review Polarity Review Sentiment  \\\n",
       "0                               0         0.550000         Positive   \n",
       "1                               6         0.512891         Positive   \n",
       "2                               4         0.178750         Positive   \n",
       "3                               1         0.133750         Positive   \n",
       "4                               4         0.171635         Positive   \n",
       "\n",
       "   Review Subjectivity  Review Length  Review Word Count  ... Reviewer Age  \\\n",
       "0             0.250000            124                 22  ...           50   \n",
       "1             0.137500            192                 36  ...           47   \n",
       "2             0.066250            488                 98  ...           49   \n",
       "3             0.215556            496                101  ...           39   \n",
       "4            -0.007692            482                 97  ...           39   \n",
       "\n",
       "  Reviewer Age Category  Emotion Emotion Score        Division  Department  \\\n",
       "0                 45-54      Joy      0.972142  General Petite     Bottoms   \n",
       "1                 45-54      Joy      0.844207         General        Tops   \n",
       "2                 45-54      Joy      0.668897         General     Dresses   \n",
       "3                 35-44      Joy      0.573683  General Petite        Tops   \n",
       "4                 35-44      Joy      0.554208  General Petite        Tops   \n",
       "\n",
       "  Product ID  Product Name  Product Category Recommended?  \n",
       "0       1049  Product 1049             Pants            1  \n",
       "1        847   Product 847           Blouses            1  \n",
       "2       1080  Product 1080           Dresses            0  \n",
       "3        858   Product 858             Knits            1  \n",
       "4        858   Product 858             Knits            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joy        1588\n",
       "Sadness     137\n",
       "Anger        15\n",
       "Fear         13\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {\n",
    "    'Joy': 0,\n",
    "    'Sadness': 1,\n",
    "    'Fear': 2,\n",
    "    'Anger': 3\n",
    "}\n",
    "\n",
    "reverse_emotion_map = {v:k for k,v in emotion_map.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Positive Feedback Count</th>\n",
       "      <th>Review Polarity</th>\n",
       "      <th>Review Sentiment</th>\n",
       "      <th>Review Subjectivity</th>\n",
       "      <th>Review Length</th>\n",
       "      <th>Review Word Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Reviewer Age Category</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion Score</th>\n",
       "      <th>Division</th>\n",
       "      <th>Department</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Recommended?</th>\n",
       "      <th>Emotion Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.972142</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>1049</td>\n",
       "      <td>Product 1049</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.512891</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>192</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.844207</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>847</td>\n",
       "      <td>Product 847</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>488</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.668897</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>Product 1080</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>496</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.573683</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shimmer, surprisingly goes with lots</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>482</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.554208</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                          Review Title  \\\n",
       "0      1                      My favorite buy!   \n",
       "1      2                      Flattering shirt   \n",
       "2      3               Not for the very petite   \n",
       "3      4                  Cagrcoal shimmer fun   \n",
       "4      5  Shimmer, surprisingly goes with lots   \n",
       "\n",
       "                                         Review Text  Review Rating  \\\n",
       "0  I love, love, love this jumpsuit. it's fun, fl...              5   \n",
       "1  This shirt is very flattering to all due to th...              5   \n",
       "2  I love tracy reese dresses, but this one is no...              2   \n",
       "3  I aded this in my basket at hte last mintue to...              5   \n",
       "4  I ordered this in carbon for store pick up, an...              4   \n",
       "\n",
       "   Review Positive Feedback Count  Review Polarity Review Sentiment  \\\n",
       "0                               0         0.550000         Positive   \n",
       "1                               6         0.512891         Positive   \n",
       "2                               4         0.178750         Positive   \n",
       "3                               1         0.133750         Positive   \n",
       "4                               4         0.171635         Positive   \n",
       "\n",
       "   Review Subjectivity  Review Length  Review Word Count  ...  \\\n",
       "0             0.250000            124                 22  ...   \n",
       "1             0.137500            192                 36  ...   \n",
       "2             0.066250            488                 98  ...   \n",
       "3             0.215556            496                101  ...   \n",
       "4            -0.007692            482                 97  ...   \n",
       "\n",
       "  Reviewer Age Category Emotion  Emotion Score        Division Department  \\\n",
       "0                 45-54     Joy       0.972142  General Petite    Bottoms   \n",
       "1                 45-54     Joy       0.844207         General       Tops   \n",
       "2                 45-54     Joy       0.668897         General    Dresses   \n",
       "3                 35-44     Joy       0.573683  General Petite       Tops   \n",
       "4                 35-44     Joy       0.554208  General Petite       Tops   \n",
       "\n",
       "   Product ID  Product Name Product Category  Recommended? Emotion Code  \n",
       "0        1049  Product 1049            Pants             1            0  \n",
       "1         847   Product 847          Blouses             1            0  \n",
       "2        1080  Product 1080          Dresses             0            0  \n",
       "3         858   Product 858            Knits             1            0  \n",
       "4         858   Product 858            Knits             1            0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['Emotion Code'] = df_reviews['Emotion']\n",
    "df_reviews = df_reviews.replace({'Emotion Code': emotion_map})\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1753 entries, 0 to 1752\n",
      "Data columns (total 23 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   index                           1753 non-null   int64  \n",
      " 1   Review Title                    1753 non-null   object \n",
      " 2   Review Text                     1753 non-null   object \n",
      " 3   Review Rating                   1753 non-null   int64  \n",
      " 4   Review Positive Feedback Count  1753 non-null   int64  \n",
      " 5   Review Polarity                 1753 non-null   float64\n",
      " 6   Review Sentiment                1753 non-null   object \n",
      " 7   Review Subjectivity             1753 non-null   float64\n",
      " 8   Review Length                   1753 non-null   int64  \n",
      " 9   Review Word Count               1753 non-null   int64  \n",
      " 10  Review Text Cleaned             1753 non-null   object \n",
      " 11  Review Text Wordcloud           1753 non-null   object \n",
      " 12  Reviewer Age                    1753 non-null   int64  \n",
      " 13  Reviewer Age Category           1753 non-null   object \n",
      " 14  Emotion                         1753 non-null   object \n",
      " 15  Emotion Score                   1753 non-null   float64\n",
      " 16  Division                        1753 non-null   object \n",
      " 17  Department                      1753 non-null   object \n",
      " 18  Product ID                      1753 non-null   int64  \n",
      " 19  Product Name                    1753 non-null   object \n",
      " 20  Product Category                1753 non-null   object \n",
      " 21  Recommended?                    1753 non-null   int64  \n",
      " 22  Emotion Code                    1753 non-null   int64  \n",
      "dtypes: float64(3), int64(9), object(11)\n",
      "memory usage: 315.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_reviews.drop(columns='Emotion Code'), df_reviews['Emotion Code'], test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "df_reviews_train = pd.DataFrame(X_train, columns=df_reviews.columns[:-1])#.reset_index(drop=True, inplace=True)\n",
    "df_reviews_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_reviews_val = pd.DataFrame(X_val, columns=df_reviews.columns[:-1])#.reset_index(drop=True, inplace=True)\n",
    "df_reviews_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the reviews\n",
    "#n = df_reviews.shape[0] // len(df_reviews['Emotion Code'].unique())\n",
    "#df_reviews = df_reviews.groupby(\"Emotion Code\").sample(n=n, random_state=42, replace=True)\n",
    "#df_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1264\n",
       "1     115\n",
       "3      12\n",
       "2      11\n",
       "Name: Emotion Code, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(encoding='utf-8', ngram_range=TFIDF_NGRAM_RANGE, stop_words=None, lowercase=False, max_df=TFIDF_MAX_DF, min_df=TFIDF_MIN_DF, max_features=TFIDF_MAX_FEATURES, norm='l2', sublinear_tf=True)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df_reviews_train['Review Text Wordcloud']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(tfidf_vectorizer, f\"{DATA_OUT_FOLDER}{VECTORIZER_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ngrams(emotion_code : int, y : pd.Series):\n",
    "\n",
    "    features_chi2 = chi2(tfidf_features, y == emotion_code) # For the current emotion, use chi2 stats to evaluate the highest correlations with the target\n",
    "    indices = np.argsort(features_chi2[0])[::-1] # np.argsort returns the indices that would sort the array ascending, [::-1] makes it descending with the highest correlation in first place\n",
    "    feature_names = np.array(tfidf_vectorizer.get_feature_names())[indices] # get_feature_names uses the sorted indices to order the features most to least correlated with the target\n",
    "    \n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1] # Selects the feature names that are single words\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2] # Selects the feature names that are two words\n",
    "    \n",
    "    return unigrams, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger:\n",
      "Most correleated unigrams: problem, neck, bra, cami, bust, purchased, reviews, sheer, reviewers, pink, going, need, small, underneath, actually, said, area, sleeves, seems, gorgeous\n",
      "Most correleated bigrams: size small, usually wear, true size, love top, looks great\n",
      "\n",
      "Fear:\n",
      "Most correleated unigrams: vest, chest, part, slightly, shoulders, way, sized, price, could, neck, say, body, expected, glad, returned, smaller, big, another, longer, flowy\n",
      "Most correleated bigrams: ordered size, love dress, love top, looks great, well made\n",
      "\n",
      "Joy:\n",
      "Most correleated unigrams: disappointed, back, wanted, return, great, way, like, bra, wide, love, going, perfect, looked, vest, part, area, bust, comfortable, first, ordered\n",
      "Most correleated bigrams: looks great, true size, cannot wait, fits perfectly, love top\n",
      "\n",
      "Sadness:\n",
      "Most correleated unigrams: disappointed, wanted, like, wide, return, great, back, love, looked, perfect, way, going, unfortunately, first, ordered, comfortable, bra, lace, would, keep\n",
      "Most correleated bigrams: looks great, true size, cannot wait, fits perfectly, love top\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for emotion, emotion_code in sorted(emotion_map.items()):\n",
    "    unigrams, bigrams = get_correlated_ngrams(emotion_code, y_train)\n",
    "    \n",
    "    print(f\"{emotion}:\")\n",
    "    print(f\"Most correleated unigrams: {', '.join(unigrams[:20])}\")\n",
    "    print(f\"Most correleated bigrams: {', '.join(bigrams[:5])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with 2000 calls into the IBM Watson API and by sampling the data we have a plausible looking set of top unigrams to feed into our own customised algorithm!!\n",
    "\n",
    "So, ... we can now try joining the tfid_features onto the main data, splitting into train and test and building an algorithm ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1402 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4         5    6    7    8    9    ...  290  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...   ...  ...  ...  ...  ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "1397  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1398  0.0  0.0  0.0  0.0  0.0  0.325123  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1399  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1400  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1401  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "           291       292  293       294  295       296  297       298  299  \n",
       "0     0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "1     0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "2     0.000000  0.000000  0.0  0.308384  0.0  0.000000  0.0  0.440473  0.0  \n",
       "3     0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "4     0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "...        ...       ...  ...       ...  ...       ...  ...       ...  ...  \n",
       "1397  0.000000  0.226468  0.0  0.000000  0.0  0.141152  0.0  0.000000  0.0  \n",
       "1398  0.000000  0.000000  0.0  0.282053  0.0  0.000000  0.0  0.000000  0.0  \n",
       "1399  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "1400  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "1401  0.193175  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.000000  0.0  \n",
       "\n",
       "[1402 rows x 300 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1402 entries, 0 to 1401\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   index                           1402 non-null   int64  \n",
      " 1   Review Title                    1402 non-null   object \n",
      " 2   Review Text                     1402 non-null   object \n",
      " 3   Review Rating                   1402 non-null   int64  \n",
      " 4   Review Positive Feedback Count  1402 non-null   int64  \n",
      " 5   Review Polarity                 1402 non-null   float64\n",
      " 6   Review Sentiment                1402 non-null   object \n",
      " 7   Review Subjectivity             1402 non-null   float64\n",
      " 8   Review Length                   1402 non-null   int64  \n",
      " 9   Review Word Count               1402 non-null   int64  \n",
      " 10  Review Text Cleaned             1402 non-null   object \n",
      " 11  Review Text Wordcloud           1402 non-null   object \n",
      " 12  Reviewer Age                    1402 non-null   int64  \n",
      " 13  Reviewer Age Category           1402 non-null   object \n",
      " 14  Emotion                         1402 non-null   object \n",
      " 15  Emotion Score                   1402 non-null   float64\n",
      " 16  Division                        1402 non-null   object \n",
      " 17  Department                      1402 non-null   object \n",
      " 18  Product ID                      1402 non-null   int64  \n",
      " 19  Product Name                    1402 non-null   object \n",
      " 20  Product Category                1402 non-null   object \n",
      " 21  Recommended?                    1402 non-null   int64  \n",
      "dtypes: float64(3), int64(8), object(11)\n",
      "memory usage: 241.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reviews_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Review Rating`` and ``Review Polarity`` are two features that intuitively would have a correlation with the emotional sentiment. Experimentation has shown that if these features are included in the model then the cross fold validation accuracy drops slightly from 0.9754566210045662 to 0.9731735159817352.\n",
    "\n",
    "However, when the trained model is run against the full file (``df_reviews_clean``) then including these two features increases the accuracy from 0.8054763262977752 0.874500855675984.\n",
    "\n",
    "The conclusion is that although the training accuracy drops marginally, the live production accuracy of the trained algorithm increases significantly if ``Review Rating`` and ``Review Polarity`` are included in the training features.\n",
    "\n",
    "However, the biggest surprise is what happens if the up-sampling of training data stage is omitted. This causes the cross fold training accuracy to reduce to 0.9132893772893773 with no predictions made for ``fear`` or ``anger`` which causes an ``UndefinedMetricWarning`` in the classification report.\n",
    "\n",
    "However, the accuracy on the full production dataset yields an accuracy of 0.9811751283513976!!\n",
    "\n",
    "We are now matching IBM Watson predictions to 98%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_reviews_train.iloc[:,[3,5]], pd.DataFrame(tfidf_features)], axis=1)\n",
    "#X = pd.DataFrame(tfidf_features)\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bug in pandas version 1.1.3 which will cause ``.info(verbose=True)`` to crash where the DataFrame contains column names that are integers (see https://github.com/pandas-dev/pandas/issues/37408).\n",
    "\n",
    "The solution is to upgrade to the latest version -\n",
    "\n",
    "```\n",
    "pip install --user --upgrade pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.5'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1402 entries, 0 to 1401\n",
      "Data columns (total 302 columns):\n",
      " #    Column           Dtype  \n",
      "---   ------           -----  \n",
      " 0    Review Rating    int64  \n",
      " 1    Review Polarity  float64\n",
      " 2    0                float64\n",
      " 3    1                float64\n",
      " 4    2                float64\n",
      " 5    3                float64\n",
      " 6    4                float64\n",
      " 7    5                float64\n",
      " 8    6                float64\n",
      " 9    7                float64\n",
      " 10   8                float64\n",
      " 11   9                float64\n",
      " 12   10               float64\n",
      " 13   11               float64\n",
      " 14   12               float64\n",
      " 15   13               float64\n",
      " 16   14               float64\n",
      " 17   15               float64\n",
      " 18   16               float64\n",
      " 19   17               float64\n",
      " 20   18               float64\n",
      " 21   19               float64\n",
      " 22   20               float64\n",
      " 23   21               float64\n",
      " 24   22               float64\n",
      " 25   23               float64\n",
      " 26   24               float64\n",
      " 27   25               float64\n",
      " 28   26               float64\n",
      " 29   27               float64\n",
      " 30   28               float64\n",
      " 31   29               float64\n",
      " 32   30               float64\n",
      " 33   31               float64\n",
      " 34   32               float64\n",
      " 35   33               float64\n",
      " 36   34               float64\n",
      " 37   35               float64\n",
      " 38   36               float64\n",
      " 39   37               float64\n",
      " 40   38               float64\n",
      " 41   39               float64\n",
      " 42   40               float64\n",
      " 43   41               float64\n",
      " 44   42               float64\n",
      " 45   43               float64\n",
      " 46   44               float64\n",
      " 47   45               float64\n",
      " 48   46               float64\n",
      " 49   47               float64\n",
      " 50   48               float64\n",
      " 51   49               float64\n",
      " 52   50               float64\n",
      " 53   51               float64\n",
      " 54   52               float64\n",
      " 55   53               float64\n",
      " 56   54               float64\n",
      " 57   55               float64\n",
      " 58   56               float64\n",
      " 59   57               float64\n",
      " 60   58               float64\n",
      " 61   59               float64\n",
      " 62   60               float64\n",
      " 63   61               float64\n",
      " 64   62               float64\n",
      " 65   63               float64\n",
      " 66   64               float64\n",
      " 67   65               float64\n",
      " 68   66               float64\n",
      " 69   67               float64\n",
      " 70   68               float64\n",
      " 71   69               float64\n",
      " 72   70               float64\n",
      " 73   71               float64\n",
      " 74   72               float64\n",
      " 75   73               float64\n",
      " 76   74               float64\n",
      " 77   75               float64\n",
      " 78   76               float64\n",
      " 79   77               float64\n",
      " 80   78               float64\n",
      " 81   79               float64\n",
      " 82   80               float64\n",
      " 83   81               float64\n",
      " 84   82               float64\n",
      " 85   83               float64\n",
      " 86   84               float64\n",
      " 87   85               float64\n",
      " 88   86               float64\n",
      " 89   87               float64\n",
      " 90   88               float64\n",
      " 91   89               float64\n",
      " 92   90               float64\n",
      " 93   91               float64\n",
      " 94   92               float64\n",
      " 95   93               float64\n",
      " 96   94               float64\n",
      " 97   95               float64\n",
      " 98   96               float64\n",
      " 99   97               float64\n",
      " 100  98               float64\n",
      " 101  99               float64\n",
      " 102  100              float64\n",
      " 103  101              float64\n",
      " 104  102              float64\n",
      " 105  103              float64\n",
      " 106  104              float64\n",
      " 107  105              float64\n",
      " 108  106              float64\n",
      " 109  107              float64\n",
      " 110  108              float64\n",
      " 111  109              float64\n",
      " 112  110              float64\n",
      " 113  111              float64\n",
      " 114  112              float64\n",
      " 115  113              float64\n",
      " 116  114              float64\n",
      " 117  115              float64\n",
      " 118  116              float64\n",
      " 119  117              float64\n",
      " 120  118              float64\n",
      " 121  119              float64\n",
      " 122  120              float64\n",
      " 123  121              float64\n",
      " 124  122              float64\n",
      " 125  123              float64\n",
      " 126  124              float64\n",
      " 127  125              float64\n",
      " 128  126              float64\n",
      " 129  127              float64\n",
      " 130  128              float64\n",
      " 131  129              float64\n",
      " 132  130              float64\n",
      " 133  131              float64\n",
      " 134  132              float64\n",
      " 135  133              float64\n",
      " 136  134              float64\n",
      " 137  135              float64\n",
      " 138  136              float64\n",
      " 139  137              float64\n",
      " 140  138              float64\n",
      " 141  139              float64\n",
      " 142  140              float64\n",
      " 143  141              float64\n",
      " 144  142              float64\n",
      " 145  143              float64\n",
      " 146  144              float64\n",
      " 147  145              float64\n",
      " 148  146              float64\n",
      " 149  147              float64\n",
      " 150  148              float64\n",
      " 151  149              float64\n",
      " 152  150              float64\n",
      " 153  151              float64\n",
      " 154  152              float64\n",
      " 155  153              float64\n",
      " 156  154              float64\n",
      " 157  155              float64\n",
      " 158  156              float64\n",
      " 159  157              float64\n",
      " 160  158              float64\n",
      " 161  159              float64\n",
      " 162  160              float64\n",
      " 163  161              float64\n",
      " 164  162              float64\n",
      " 165  163              float64\n",
      " 166  164              float64\n",
      " 167  165              float64\n",
      " 168  166              float64\n",
      " 169  167              float64\n",
      " 170  168              float64\n",
      " 171  169              float64\n",
      " 172  170              float64\n",
      " 173  171              float64\n",
      " 174  172              float64\n",
      " 175  173              float64\n",
      " 176  174              float64\n",
      " 177  175              float64\n",
      " 178  176              float64\n",
      " 179  177              float64\n",
      " 180  178              float64\n",
      " 181  179              float64\n",
      " 182  180              float64\n",
      " 183  181              float64\n",
      " 184  182              float64\n",
      " 185  183              float64\n",
      " 186  184              float64\n",
      " 187  185              float64\n",
      " 188  186              float64\n",
      " 189  187              float64\n",
      " 190  188              float64\n",
      " 191  189              float64\n",
      " 192  190              float64\n",
      " 193  191              float64\n",
      " 194  192              float64\n",
      " 195  193              float64\n",
      " 196  194              float64\n",
      " 197  195              float64\n",
      " 198  196              float64\n",
      " 199  197              float64\n",
      " 200  198              float64\n",
      " 201  199              float64\n",
      " 202  200              float64\n",
      " 203  201              float64\n",
      " 204  202              float64\n",
      " 205  203              float64\n",
      " 206  204              float64\n",
      " 207  205              float64\n",
      " 208  206              float64\n",
      " 209  207              float64\n",
      " 210  208              float64\n",
      " 211  209              float64\n",
      " 212  210              float64\n",
      " 213  211              float64\n",
      " 214  212              float64\n",
      " 215  213              float64\n",
      " 216  214              float64\n",
      " 217  215              float64\n",
      " 218  216              float64\n",
      " 219  217              float64\n",
      " 220  218              float64\n",
      " 221  219              float64\n",
      " 222  220              float64\n",
      " 223  221              float64\n",
      " 224  222              float64\n",
      " 225  223              float64\n",
      " 226  224              float64\n",
      " 227  225              float64\n",
      " 228  226              float64\n",
      " 229  227              float64\n",
      " 230  228              float64\n",
      " 231  229              float64\n",
      " 232  230              float64\n",
      " 233  231              float64\n",
      " 234  232              float64\n",
      " 235  233              float64\n",
      " 236  234              float64\n",
      " 237  235              float64\n",
      " 238  236              float64\n",
      " 239  237              float64\n",
      " 240  238              float64\n",
      " 241  239              float64\n",
      " 242  240              float64\n",
      " 243  241              float64\n",
      " 244  242              float64\n",
      " 245  243              float64\n",
      " 246  244              float64\n",
      " 247  245              float64\n",
      " 248  246              float64\n",
      " 249  247              float64\n",
      " 250  248              float64\n",
      " 251  249              float64\n",
      " 252  250              float64\n",
      " 253  251              float64\n",
      " 254  252              float64\n",
      " 255  253              float64\n",
      " 256  254              float64\n",
      " 257  255              float64\n",
      " 258  256              float64\n",
      " 259  257              float64\n",
      " 260  258              float64\n",
      " 261  259              float64\n",
      " 262  260              float64\n",
      " 263  261              float64\n",
      " 264  262              float64\n",
      " 265  263              float64\n",
      " 266  264              float64\n",
      " 267  265              float64\n",
      " 268  266              float64\n",
      " 269  267              float64\n",
      " 270  268              float64\n",
      " 271  269              float64\n",
      " 272  270              float64\n",
      " 273  271              float64\n",
      " 274  272              float64\n",
      " 275  273              float64\n",
      " 276  274              float64\n",
      " 277  275              float64\n",
      " 278  276              float64\n",
      " 279  277              float64\n",
      " 280  278              float64\n",
      " 281  279              float64\n",
      " 282  280              float64\n",
      " 283  281              float64\n",
      " 284  282              float64\n",
      " 285  283              float64\n",
      " 286  284              float64\n",
      " 287  285              float64\n",
      " 288  286              float64\n",
      " 289  287              float64\n",
      " 290  288              float64\n",
      " 291  289              float64\n",
      " 292  290              float64\n",
      " 293  291              float64\n",
      " 294  292              float64\n",
      " 295  293              float64\n",
      " 296  294              float64\n",
      " 297  295              float64\n",
      " 298  296              float64\n",
      " 299  297              float64\n",
      " 300  298              float64\n",
      " 301  299              float64\n",
      "dtypes: float64(301), int64(1)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "X.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Polarity</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.438571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.102315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.530469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.162662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review Rating  Review Polarity    0    1    2    3    4    5    6    7  \\\n",
       "0              5         0.438571  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1              5         0.102315  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2              5         0.530469  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3              4         0.162662  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4              5         0.253333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   ...  290  291  292  293       294  295  296  297       298  299  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  \n",
       "2  ...  0.0  0.0  0.0  0.0  0.308384  0.0  0.0  0.0  0.440473  0.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1264\n",
       "1     115\n",
       "3      12\n",
       "2      11\n",
       "Name: Emotion Code, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094051855617693 0.018448365695431693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=NUM_FOLDS, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "cv_results = cross_val_score(model, X, y, cv=kfold, scoring=SCORING, verbose=VERBOSE)\n",
    "print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/generation-of-a-concatenated-confusion-matrix-in-cross-validation-912485c4a972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "    predicted_proba = np.array([])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model.predict(test_X))\n",
    "        predicted_proba = np.append(predicted_proba, model.predict_proba(test_X))\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes, predicted_classes, predicted_proba = cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9094151212553495\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(actual_classes, predicted_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.9094151212553495 hints vs.  0.9015691868758916 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      1264\n",
      "         1.0       0.79      0.13      0.22       115\n",
      "         2.0       0.00      0.00      0.00        11\n",
      "         3.0       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.91      1402\n",
      "   macro avg       0.43      0.28      0.29      1402\n",
      "weighted avg       0.89      0.91      0.88      1402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHarrison\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\\n\", classification_report(actual_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some labels in y_test don't appear in y_pred. Specifically emotion codes 2 and 3 are never predicted. This means that there is no F-score to calculate for this label, and thus the F-score for this case is considered to be 0.0. See https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix : confusion_matrix, tick_labels: list):\n",
    "\n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=tick_labels, yticklabels=tick_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.ylabel('Predicted'); plt.xlabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(actual_classes, predicted_classes), list(emotion_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, f\"{DATA_OUT_FOLDER}{MODEL_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = tfidf_vectorizer.transform(df_reviews_val['Review Text Wordcloud']).toarray()\n",
    "\n",
    "X = pd.concat([df_reviews_val.iloc[:,[3,5]], pd.DataFrame(tfidf_features)], axis=1)\n",
    "#X = pd.DataFrame(tfidf_features)\n",
    "y = y_val\n",
    "\n",
    "actual_classes = y\n",
    "predicted_classes = model.predict(X)\n",
    "predicted_proba = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9316239316239316\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(actual_classes, predicted_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.9316239316239316 including hints vs. Accuracy: 0.9230769230769231 just words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       324\n",
      "           1       1.00      0.14      0.24        22\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.93       351\n",
      "   macro avg       0.48      0.28      0.30       351\n",
      "weighted avg       0.92      0.93      0.91       351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHarrison\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\\n\", classification_report(actual_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(actual_classes, predicted_classes), list(emotion_map.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "1. Convert the predicted emotion codes back to textual emotions with a nice lambda function.\n",
    "2. Append the predicted emotions and predicted probabilities into the clean data.\n",
    "3. Take a look and see what the results look like.\n",
    "4. Apply the results to all 23,000 rows (after removing the nulls).\n",
    "\n",
    "Voila!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
