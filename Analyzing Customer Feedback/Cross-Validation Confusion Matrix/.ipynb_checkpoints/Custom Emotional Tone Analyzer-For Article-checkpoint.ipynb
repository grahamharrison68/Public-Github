{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build an Emotion Tone Analyzer from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build a high-performance emotion tone analyzer to compete with IBM Watson with no transaction charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/03.%20Feature%20Engineering/03.%20Feature%20Engineering.ipynb\n",
    "\n",
    "https://github.com/miguelfzafra/Latest-News-Classifier/blob/master/0.%20Latest%20News%20Classifier/04.%20Model%20Training/06.%20MT%20-%20Random%20Forest.ipynb\n",
    "\n",
    "https://towardsdatascience.com/text-classification-in-python-dd95d264c802\n",
    "\n",
    "https://github.com/miguelfzafra/Latest-News-Classifier/tree/master/0.%20Latest%20News%20Classifier/04.%20Model%20Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the data\n",
    "2. Test train split\n",
    "3. use TFIFD to add in the new features\n",
    "4. Use an algorithm to make some predictions\n",
    "5. Assess the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_FOLDER : str = \"../data/out/\"\n",
    "DATA_OUT_FOLDER : str = \"../data/out/\"\n",
    "\n",
    "RANDOM_STATE : int = 42\n",
    "    \n",
    "SOURCE_TRAINING_DATA_FILE : str = \"Womens Clothing E-Commerce Reviews with Emotions.xlsx\"\n",
    "SOURCE_FULL_DATA_FILE : str = \"Womens Clothing E-Commerce Reviews.xlsx\"\n",
    "TARGET_FULL_DATA_FILE : str = \"Womens Clothing E-Commerce Reviews with All Emotions.xlsx\"\n",
    "    \n",
    "UTILITIES_PATH : str = r'C:\\Users\\GHarrison\\OneDrive - Lincoln College\\Python Projects\\Data Science\\Utilities'\n",
    "MODEL_FILE : str = \"ml_model.pkl\"\n",
    "VECTORIZER_FILE : str = \"vectorizer.pkl\"\n",
    "\n",
    "RANDOM_STATE : int = 42\n",
    "\n",
    "EMOTIONS : list = ['Joy', 'Sadness', 'Fear', 'Anger']\n",
    "RESAMPLE : bool = True\n",
    "    \n",
    "TFIDF_NGRAM_RANGE : tuple = (1,2)\n",
    "TFIDF_MAX_DF : float = 1.\n",
    "TFIDF_MIN_DF : int = 10\n",
    "TFIDF_MAX_FEATURES : int = 300\n",
    "    \n",
    "NUM_FOLDS : int = 5\n",
    "SCORING :str = 'accuracy'\n",
    "VERBOSE : int = 10\n",
    "SEARCH_ITERATIONS = 500\n",
    "    \n",
    "RETUNE_HYPER_PARAMS : bool = False\n",
    "USE_PRETUNED_HYPER_PARAMS : bool = True\n",
    "TUNED_HYPER_PARAMS_50 : dict = {'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}\n",
    "TUNED_HYPER_PARAMS_500 : dict = {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import copy as cp\n",
    "\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, UTILITIES_PATH)\n",
    "\n",
    "from misc_tools import load_object, save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_reviews = pd.read_excel(f\"{DATA_IN_FOLDER}{SOURCE_TRAINING_DATA_FILE}\")\n",
    "df_reviews_raw = df_reviews.copy(deep=True)\n",
    "\n",
    "df_reviews.dropna(inplace=True) \n",
    "df_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Positive Feedback Count</th>\n",
       "      <th>Review Polarity</th>\n",
       "      <th>Review Sentiment</th>\n",
       "      <th>Review Subjectivity</th>\n",
       "      <th>Review Length</th>\n",
       "      <th>Review Word Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Reviewer Age</th>\n",
       "      <th>Reviewer Age Category</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion Score</th>\n",
       "      <th>Division</th>\n",
       "      <th>Department</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Recommended?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.972142</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>1049</td>\n",
       "      <td>Product 1049</td>\n",
       "      <td>Pants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.512891</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>192</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.844207</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>847</td>\n",
       "      <td>Product 847</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>488</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.668897</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>Product 1080</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>496</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.573683</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shimmer, surprisingly goes with lots</td>\n",
       "      <td>I ordered this in carbon for store pick up, an...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>482</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.554208</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>858</td>\n",
       "      <td>Product 858</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                          Review Title  \\\n",
       "0      1                      My favorite buy!   \n",
       "1      2                      Flattering shirt   \n",
       "2      3               Not for the very petite   \n",
       "3      4                  Cagrcoal shimmer fun   \n",
       "4      5  Shimmer, surprisingly goes with lots   \n",
       "\n",
       "                                         Review Text  Review Rating  \\\n",
       "0  I love, love, love this jumpsuit. it's fun, fl...              5   \n",
       "1  This shirt is very flattering to all due to th...              5   \n",
       "2  I love tracy reese dresses, but this one is no...              2   \n",
       "3  I aded this in my basket at hte last mintue to...              5   \n",
       "4  I ordered this in carbon for store pick up, an...              4   \n",
       "\n",
       "   Review Positive Feedback Count  Review Polarity Review Sentiment  \\\n",
       "0                               0         0.550000         Positive   \n",
       "1                               6         0.512891         Positive   \n",
       "2                               4         0.178750         Positive   \n",
       "3                               1         0.133750         Positive   \n",
       "4                               4         0.171635         Positive   \n",
       "\n",
       "   Review Subjectivity  Review Length  Review Word Count  ... Reviewer Age  \\\n",
       "0             0.250000            124                 22  ...           50   \n",
       "1             0.137500            192                 36  ...           47   \n",
       "2             0.066250            488                 98  ...           49   \n",
       "3             0.215556            496                101  ...           39   \n",
       "4            -0.007692            482                 97  ...           39   \n",
       "\n",
       "  Reviewer Age Category  Emotion Emotion Score        Division  Department  \\\n",
       "0                 45-54      Joy      0.972142  General Petite     Bottoms   \n",
       "1                 45-54      Joy      0.844207         General        Tops   \n",
       "2                 45-54      Joy      0.668897         General     Dresses   \n",
       "3                 35-44      Joy      0.573683  General Petite        Tops   \n",
       "4                 35-44      Joy      0.554208  General Petite        Tops   \n",
       "\n",
       "  Product ID  Product Name  Product Category Recommended?  \n",
       "0       1049  Product 1049             Pants            1  \n",
       "1        847   Product 847           Blouses            1  \n",
       "2       1080  Product 1080           Dresses            0  \n",
       "3        858   Product 858             Knits            1  \n",
       "4        858   Product 858             Knits            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1753 entries, 0 to 1752\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   index                           1753 non-null   int64  \n",
      " 1   Review Title                    1753 non-null   object \n",
      " 2   Review Text                     1753 non-null   object \n",
      " 3   Review Rating                   1753 non-null   int64  \n",
      " 4   Review Positive Feedback Count  1753 non-null   int64  \n",
      " 5   Review Polarity                 1753 non-null   float64\n",
      " 6   Review Sentiment                1753 non-null   object \n",
      " 7   Review Subjectivity             1753 non-null   float64\n",
      " 8   Review Length                   1753 non-null   int64  \n",
      " 9   Review Word Count               1753 non-null   int64  \n",
      " 10  Review Text Cleaned             1753 non-null   object \n",
      " 11  Review Text Wordcloud           1753 non-null   object \n",
      " 12  Reviewer Age                    1753 non-null   int64  \n",
      " 13  Reviewer Age Category           1753 non-null   object \n",
      " 14  Emotion                         1753 non-null   object \n",
      " 15  Emotion Score                   1753 non-null   float64\n",
      " 16  Division                        1753 non-null   object \n",
      " 17  Department                      1753 non-null   object \n",
      " 18  Product ID                      1753 non-null   int64  \n",
      " 19  Product Name                    1753 non-null   object \n",
      " 20  Product Category                1753 non-null   object \n",
      " 21  Recommended?                    1753 non-null   int64  \n",
      "dtypes: float64(3), int64(8), object(11)\n",
      "memory usage: 301.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_train, df_reviews_val = train_test_split(df_reviews, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "df_reviews_train.reset_index(drop=True, inplace=True)\n",
    "df_reviews_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_reviews_train = df_reviews_train.copy(deep=True)\n",
    "df_reviews_val = df_reviews_val.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the reviews\n",
    "if RESAMPLE == True:\n",
    "    n = df_reviews_train.shape[0] // len(df_reviews_train['Emotion'].unique())\n",
    "    df_reviews_train = df_reviews_train.groupby(\"Emotion\").sample(n=n, random_state=RANDOM_STATE, replace=True)\n",
    "    df_reviews_train.reset_index(drop=True, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anger      350\n",
       "Fear       350\n",
       "Joy        350\n",
       "Sadness    350\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_train['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(encoding='utf-8', ngram_range=TFIDF_NGRAM_RANGE, stop_words=None, lowercase=False, max_df=TFIDF_MAX_DF, min_df=TFIDF_MIN_DF, max_features=TFIDF_MAX_FEATURES, norm='l2', sublinear_tf=True)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df_reviews_train['Review Text Wordcloud']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlated_ngrams(emotion_code : int, y : pd.Series):\n",
    "\n",
    "    features_chi2 = chi2(tfidf_features, y == emotion_code) # For the current emotion, use chi2 stats to evaluate the highest correlations with the target\n",
    "    indices = np.argsort(features_chi2[0])[::-1] # np.argsort returns the indices that would sort the array ascending, [::-1] makes it descending with the highest correlation in first place\n",
    "    feature_names = np.array(tfidf_vectorizer.get_feature_names())[indices] # get_feature_names uses the sorted indices to order the features most to least correlated with the target\n",
    "    \n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1] # Selects the feature names that are single words\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2] # Selects the feature names that are two words\n",
    "    \n",
    "    return unigrams, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joy:\n",
      "Most correleated unigrams: fits, great, comfortable, got, true, nice, pounds, love, perfect, bad, length, lay, petite, much, disappointed, across, pulled, though, bust, skirt\n",
      "Most correleated bigrams: true size, runs slightly, need wear, dry clean, fabric bad\n",
      "\n",
      "Sadness:\n",
      "Most correleated unigrams: wanted, sad, disappointed, get, saw, like, pounds, great, wore, love, lay, size, even, much, material, received, first, would, across, still\n",
      "Most correleated bigrams: need wear, runs slightly, going back, fabric bad, pounds usually\n",
      "\n",
      "Fear:\n",
      "Most correleated unigrams: across, pulled, shoulders, fear, squareapple, underlayer, types, si, narrow, done, space, slightly, romper, different, way, vest, chest, part, glad, guess\n",
      "Most correleated bigrams: runs slightly, types fabric, small athletic, little short, space arms\n",
      "\n",
      "Anger:\n",
      "Most correleated unigrams: problem, strike, flat, pounds, idea, dressy, purchased, deep, zipper, mentioned, small, shows, appears, reviewers, lay, sheer, reviews, pants, cami, pink\n",
      "Most correleated bigrams: need wear, pounds usually, reviewers mentioned, sale price, runs slightly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for emotion, emotion_code in sorted(emotion_map.items()):\n",
    "for emotion in EMOTIONS:\n",
    "    #unigrams, bigrams = get_correlated_ngrams(emotion_code, y_train)\n",
    "    unigrams, bigrams = get_correlated_ngrams(emotion, df_reviews_train['Emotion'])\n",
    "    \n",
    "    print(f\"{emotion}:\")\n",
    "    print(f\"Most correleated unigrams: {', '.join(unigrams[:20])}\")\n",
    "    print(f\"Most correleated bigrams: {', '.join(bigrams[:5])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with 2000 calls into the IBM Watson API and by sampling the data we have a plausible looking set of top unigrams to feed into our own customised algorithm!!\n",
    "\n",
    "So, ... we can now try joining the tfid_features onto the main data, splitting into train and test and building an algorithm ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.264608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1         2    3    4    5         6    7    8         9    ...  \\\n",
       "0     0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "1     0.0  0.2167  0.000000  0.0  0.0  0.0  0.255693  0.0  0.0  0.410525  ...   \n",
       "2     0.0  0.0000  0.264608  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "3     0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "4     0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "...   ...     ...       ...  ...  ...  ...       ...  ...  ...       ...  ...   \n",
       "1395  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "1396  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "1397  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "1398  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "1399  0.0  0.0000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  ...   \n",
       "\n",
       "           290  291  292       293       294  295  296  297  298       299  \n",
       "0     0.000000  0.0  0.0  0.219097  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "1     0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "2     0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.557767  \n",
       "3     0.244544  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "4     0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "...        ...  ...  ...       ...       ...  ...  ...  ...  ...       ...  \n",
       "1395  0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "1396  0.000000  0.0  0.0  0.235703  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "1397  0.220163  0.0  0.0  0.000000  0.132845  0.0  0.0  0.0  0.0  0.000000  \n",
       "1398  0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "1399  0.000000  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  \n",
       "\n",
       "[1400 rows x 300 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([df_reviews_train.iloc[:,[3,5]], pd.DataFrame(tfidf_features)], axis=1)\n",
    "y_train = df_reviews_train['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Review Positive Feedback Count</th>\n",
       "      <th>Review Polarity</th>\n",
       "      <th>Review Sentiment</th>\n",
       "      <th>Review Subjectivity</th>\n",
       "      <th>Review Length</th>\n",
       "      <th>Review Word Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Review Text Wordcloud</th>\n",
       "      <th>Reviewer Age</th>\n",
       "      <th>Reviewer Age Category</th>\n",
       "      <th>Emotion Score</th>\n",
       "      <th>Division</th>\n",
       "      <th>Department</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Recommended?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1472</td>\n",
       "      <td>Surprisingly flattering...plus pockets!!!</td>\n",
       "      <td>I tried this dress on in my local retailer and...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199802</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.056944</td>\n",
       "      <td>502</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>tried dress local retailer pleasantly surprise...</td>\n",
       "      <td>41</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0.688244</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1095</td>\n",
       "      <td>Product 1095</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1031</td>\n",
       "      <td>Not as pictured</td>\n",
       "      <td>I ordered this dress in the blood orange and h...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.143452</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.315476</td>\n",
       "      <td>351</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>ordered dress blood orange complaints appears ...</td>\n",
       "      <td>63</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0.554221</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1095</td>\n",
       "      <td>Product 1095</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233</td>\n",
       "      <td>Bad zipper</td>\n",
       "      <td>Beautiful dress with the colors and pleats. i ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.380000</td>\n",
       "      <td>282</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>beautiful dress colors pleats problems bust ar...</td>\n",
       "      <td>36</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0.661359</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1080</td>\n",
       "      <td>Product 1080</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1792</td>\n",
       "      <td>Awesome shirt</td>\n",
       "      <td>I am 5'10\", 130 pounds. a medium is a perfect ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337245</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>281</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>pounds medium perfect fit love sheer feel need...</td>\n",
       "      <td>49</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0.694794</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>872</td>\n",
       "      <td>Product 872</td>\n",
       "      <td>Knits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>Beautiful and timeless</td>\n",
       "      <td>I am 5.6\", 138 pounds. i purchased this in a s...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304040</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.167677</td>\n",
       "      <td>206</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>pounds purchased size small flowy short comfor...</td>\n",
       "      <td>47</td>\n",
       "      <td>45-54</td>\n",
       "      <td>0.664082</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>844</td>\n",
       "      <td>Product 844</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>462</td>\n",
       "      <td>Comfortable, soft</td>\n",
       "      <td>The material is very soft and it looks just li...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.085833</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.296667</td>\n",
       "      <td>206</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>material soft looks like model exception gets ...</td>\n",
       "      <td>39</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0.523228</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>995</td>\n",
       "      <td>Product 995</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1677</td>\n",
       "      <td>Very cute but...</td>\n",
       "      <td>I ordered a 6p in this dress so it wld fall ab...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.115152</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.427739</td>\n",
       "      <td>500</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>ordered dress wld fall knees slightly smaller ...</td>\n",
       "      <td>64</td>\n",
       "      <td>55-64</td>\n",
       "      <td>0.549360</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1095</td>\n",
       "      <td>Product 1095</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>645</td>\n",
       "      <td>If only it looked like the photo.....</td>\n",
       "      <td>This sweater was a big let down. i am 5'2\" so ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.211444</td>\n",
       "      <td>411</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>sweater big let ordered petite short lifted ar...</td>\n",
       "      <td>43</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0.535870</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>945</td>\n",
       "      <td>Product 945</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>158</td>\n",
       "      <td>Not worth cost</td>\n",
       "      <td>Bought this item on sale and was very disappoi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>274</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>bought item sale disappointed quality cost fab...</td>\n",
       "      <td>36</td>\n",
       "      <td>35-44</td>\n",
       "      <td>0.681196</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>895</td>\n",
       "      <td>Product 895</td>\n",
       "      <td>Fine gauge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1086</td>\n",
       "      <td>Cute shirt, but not for me</td>\n",
       "      <td>The blue lace with the white top underneath is...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>127</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>blue lace white top underneath pretty unfortun...</td>\n",
       "      <td>25</td>\n",
       "      <td>25-34</td>\n",
       "      <td>0.560817</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>836</td>\n",
       "      <td>Product 836</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                               Review Title  \\\n",
       "0      1472  Surprisingly flattering...plus pockets!!!   \n",
       "1      1031                            Not as pictured   \n",
       "2      1233                                 Bad zipper   \n",
       "3      1792                              Awesome shirt   \n",
       "4       273                     Beautiful and timeless   \n",
       "...     ...                                        ...   \n",
       "1395    462                          Comfortable, soft   \n",
       "1396   1677                           Very cute but...   \n",
       "1397    645      If only it looked like the photo.....   \n",
       "1398    158                             Not worth cost   \n",
       "1399   1086                 Cute shirt, but not for me   \n",
       "\n",
       "                                            Review Text  Review Rating  \\\n",
       "0     I tried this dress on in my local retailer and...              4   \n",
       "1     I ordered this dress in the blood orange and h...              2   \n",
       "2     Beautiful dress with the colors and pleats. i ...              3   \n",
       "3     I am 5'10\", 130 pounds. a medium is a perfect ...              5   \n",
       "4     I am 5.6\", 138 pounds. i purchased this in a s...              5   \n",
       "...                                                 ...            ...   \n",
       "1395  The material is very soft and it looks just li...              4   \n",
       "1396  I ordered a 6p in this dress so it wld fall ab...              4   \n",
       "1397  This sweater was a big let down. i am 5'2\" so ...              1   \n",
       "1398  Bought this item on sale and was very disappoi...              3   \n",
       "1399  The blue lace with the white top underneath is...              5   \n",
       "\n",
       "      Review Positive Feedback Count  Review Polarity Review Sentiment  \\\n",
       "0                                  0         0.199802         Positive   \n",
       "1                                  1        -0.143452         Negative   \n",
       "2                                  0         0.105000         Positive   \n",
       "3                                  0         0.337245         Positive   \n",
       "4                                  0         0.304040         Positive   \n",
       "...                              ...              ...              ...   \n",
       "1395                               0        -0.085833         Negative   \n",
       "1396                               9         0.115152         Positive   \n",
       "1397                               8         0.021694          Neutral   \n",
       "1398                               0         0.092708         Positive   \n",
       "1399                               0         0.065000         Positive   \n",
       "\n",
       "      Review Subjectivity  Review Length  Review Word Count  ...  \\\n",
       "0                0.056944            502                 98  ...   \n",
       "1               -0.315476            351                 65  ...   \n",
       "2               -0.380000            282                 51  ...   \n",
       "3                0.153061            281                 59  ...   \n",
       "4                0.167677            206                 39  ...   \n",
       "...                   ...            ...                ...  ...   \n",
       "1395            -0.296667            206                 44  ...   \n",
       "1396            -0.427739            500                106  ...   \n",
       "1397            -0.211444            411                 84  ...   \n",
       "1398             0.068750            274                 50  ...   \n",
       "1399             0.040000            127                 24  ...   \n",
       "\n",
       "                                  Review Text Wordcloud Reviewer Age  \\\n",
       "0     tried dress local retailer pleasantly surprise...           41   \n",
       "1     ordered dress blood orange complaints appears ...           63   \n",
       "2     beautiful dress colors pleats problems bust ar...           36   \n",
       "3     pounds medium perfect fit love sheer feel need...           49   \n",
       "4     pounds purchased size small flowy short comfor...           47   \n",
       "...                                                 ...          ...   \n",
       "1395  material soft looks like model exception gets ...           39   \n",
       "1396  ordered dress wld fall knees slightly smaller ...           64   \n",
       "1397  sweater big let ordered petite short lifted ar...           43   \n",
       "1398  bought item sale disappointed quality cost fab...           36   \n",
       "1399  blue lace white top underneath pretty unfortun...           25   \n",
       "\n",
       "      Reviewer Age Category Emotion Score        Division Department  \\\n",
       "0                     35-44      0.688244  General Petite    Dresses   \n",
       "1                     55-64      0.554221         General    Dresses   \n",
       "2                     35-44      0.661359         General    Dresses   \n",
       "3                     45-54      0.694794         General       Tops   \n",
       "4                     45-54      0.664082  General Petite       Tops   \n",
       "...                     ...           ...             ...        ...   \n",
       "1395                  35-44      0.523228         General    Bottoms   \n",
       "1396                  55-64      0.549360  General Petite    Dresses   \n",
       "1397                  35-44      0.535870         General       Tops   \n",
       "1398                  35-44      0.681196         General       Tops   \n",
       "1399                  25-34      0.560817         General       Tops   \n",
       "\n",
       "     Product ID  Product Name Product Category Recommended?  \n",
       "0          1095  Product 1095          Dresses            1  \n",
       "1          1095  Product 1095          Dresses            0  \n",
       "2          1080  Product 1080          Dresses            0  \n",
       "3           872   Product 872            Knits            1  \n",
       "4           844   Product 844          Blouses            1  \n",
       "...         ...           ...              ...          ...  \n",
       "1395        995   Product 995           Skirts            1  \n",
       "1396       1095  Product 1095          Dresses            1  \n",
       "1397        945   Product 945         Sweaters            0  \n",
       "1398        895   Product 895       Fine gauge            0  \n",
       "1399        836   Product 836          Blouses            0  \n",
       "\n",
       "[1400 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_train.drop([\"Emotion\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "kfold = KFold(n_splits=NUM_FOLDS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RETUNE_HYPER_PARAMS == True:\n",
    "    \n",
    "    search_spaces_grid = {\n",
    "                         'n_estimators': np.linspace(200, 1000, 5, dtype=int), \n",
    "                         'max_features': ['auto', 'sqrt'], \n",
    "                         'max_depth': np.linspace(20, 100, 5, dtype=int), \n",
    "                         'min_samples_split': [2, 5, 10], \n",
    "                         'min_samples_leaf': [1, 2, 4], \n",
    "                         'bootstrap': [True, False]\n",
    "                         }\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator=model,\n",
    "                                       param_distributions=search_spaces_grid,\n",
    "                                       n_iter=SEARCH_ITERATIONS,\n",
    "                                       scoring=SCORING,\n",
    "                                       cv=kfold, \n",
    "                                       verbose=VERBOSE, \n",
    "                                       random_state=RANDOM_STATE)\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    model.set_params(**random_search.best_params_, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETUNE_HYPER_PARAMS == True:\n",
    "    print(random_search.best_score_)\n",
    "    print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PRETUNED_HYPER_PARAMS == True:\n",
    "    model.set_params(**TUNED_HYPER_PARAMS_500, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.971, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.989, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.979, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.989, total=   0.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.982, total=   0.5s\n",
      "0.9821428571428571 0.006776309271789407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=SCORING, verbose=VERBOSE)\n",
    "print(cv_results.mean(), cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Tuned accuracy / std: 0.9317505030181087 0.023980459693619532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/generation-of-a-concatenated-confusion-matrix-in-cross-validation-912485c4a972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "    return actual_classes, predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes, predicted_classes = cross_val_predict(model, kfold, X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.9094151212553495 hints vs.  0.9015691868758916 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some labels in y_test don't appear in y_pred. Specifically emotion codes 2 and 3 are never predicted. This means that there is no F-score to calculate for this label, and thus the F-score for this case is considered to be 0.0. See https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(unique, counts) = numpy.unique(number_list, return_counts=True)\n",
    "#frequencies = numpy.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array, sorted_labels : list):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Anger       1.00      1.00      1.00       350\n",
      "        Fear       1.00      1.00      1.00       350\n",
      "         Joy       0.97      0.95      0.96       350\n",
      "     Sadness       0.96      0.97      0.96       350\n",
      "\n",
      "    accuracy                           0.98      1400\n",
      "   macro avg       0.98      0.98      0.98      1400\n",
      "weighted avg       0.98      0.98      0.98      1400\n",
      "\n",
      "Accuracy: 0.9821428571428571\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Classification report\\n\", classification_report(actual_classes, predicted_classes))\n",
    "print(f\"Accuracy: {accuracy_score(actual_classes, predicted_classes)}\")\n",
    "plot_confusion_matrix(actual_classes, predicted_classes, EMOTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "tfidf_features = tfidf_vectorizer.transform(df_reviews_val['Review Text Wordcloud']).toarray()\n",
    "\n",
    "X_val = pd.concat([df_reviews_val.iloc[:,[3,5]], pd.DataFrame(tfidf_features)], axis=1)\n",
    "y_val = df_reviews_val['Emotion']\n",
    "\n",
    "actual_classes = y_val\n",
    "predicted_classes = model.predict(X_val)\n",
    "predicted_proba = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, f\"{DATA_OUT_FOLDER}{MODEL_FILE}\")\n",
    "save_object(tfidf_vectorizer, f\"{DATA_OUT_FOLDER}{VECTORIZER_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.00      0.00      0.00         3\n",
      "        Fear       0.00      0.00      0.00         2\n",
      "         Joy       0.97      0.93      0.95       324\n",
      "     Sadness       0.39      0.73      0.51        22\n",
      "\n",
      "    accuracy                           0.90       351\n",
      "   macro avg       0.34      0.41      0.36       351\n",
      "weighted avg       0.92      0.90      0.91       351\n",
      "\n",
      "Accuracy: 0.9031339031339032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHarrison\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAGDCAYAAADeXFNvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy6UlEQVR4nO3deZxcVZn/8c83CWEHCZAEJYJsOoAsIzLuAi4gi4CAoI7DKBoXXHAHZXDFl9vojI5bEJXBBXFhBEFQUUD9Kavsi6IgREIQkB0hhOf3R91gE5JOp7urq+ryefO6r666de89p5qb7qefes45qSokSZKkQTep1x2QJEmSxoOBrSRJklrBwFaSJEmtYGArSZKkVjCwlSRJUisY2EqSJKkVDGwl9bUkKyc5KcntSb47huu8IslPxrNvvZDkx0kO7HU/JKkfGdhKGhdJXp7kvCR3JZnXBGDPGodL7wvMANauqv1Ge5Gq+mZVvXAc+vMwSXZIUkl+sNj+rZv9Z4zwOh9I8o1lHVdVL6qqY0bZXUlqNQNbSWOW5O3AfwEfpROEPh74ArDnOFx+A+D3VfXAOFyrW/4KPCPJ2kP2HQj8frwaSIc/syVpGP6QlDQmSdYEPgQcXFU/qKq7q2pBVZ1UVe9qjlkxyX8luaHZ/ivJis1rOySZm+QdSW5qsr2val77IHAEsH+TCT5o8cxmkg2bzOiU5vm/J/lTkjuTXJPkFUP2/2rIec9Icm5T4nBukmcMee2MJB9O8uvmOj9Jss4w34b7gf8DDmjOnwy8FPjmYt+r/05yfZI7kpyf5NnN/l2A9w55nxcN6ceRSX4N3ANs1Ox7TfP6F5N8b8j1P57k9CQZ6f8/SWoTA1tJY/V0YCXghGGOeR/wNGAbYGtge+DwIa/PBNYEHgccBHw+yVpV9X46WeDvVNVqVXX0cB1JsirwWeBFVbU68AzgwiUcNw04uTl2beDTwMmLZVxfDrwKmA5MBd45XNvA/wL/1jzeGbgMuGGxY86l8z2YBnwL+G6Slarq1MXe59ZDznklMBtYHfjzYtd7B7BVE7Q/m8737sByrXRJj1IGtpLGam3g5mWUCrwC+FBV3VRVfwU+SCdgW2RB8/qCqjoFuAt44ij78yCwZZKVq2peVV22hGN2A/5QVcdW1QNV9W3gSmCPIcd8rap+X1X3AsfTCUiXqqr+HzAtyRPpBLj/u4RjvlFVtzRt/iewIst+n1+vqsuacxYsdr17gH+lE5h/A3hzVc1dxvUkqbUMbCWN1S3AOotKAZbisTw82/jnZt9D11gsML4HWG15O1JVdwP7A68H5iU5OcmTRtCfRX163JDnN46iP8cCbwJ2ZAkZ7Kbc4oqm/OE2Olnq4UocAK4f7sWqOgf4ExA6AbgkPWoZ2Eoaq98Afwf2GuaYG+gMAlvk8TzyY/qRuhtYZcjzmUNfrKrTquoFwHp0srBHjaA/i/r0l1H2aZFjgTcCpzTZ1Ic0pQLvoVN7u1ZVPQa4nU5ACrC08oFhywqSHEwn83sD8O5R91ySWsDAVtKYVNXtdAZ4fT7JXklWSbJCkhcl+URz2LeBw5Os2wzCOoLOR+ejcSHwnCSPbwauHbbohSQzkry4qbW9j05Jw8IlXOMUYLNmirIpSfYHNgd+NMo+AVBV1wDPpVNTvLjVgQfozKAwJckRwBpDXp8PbLg8Mx8k2Qz4CJ1yhFcC706yzeh6L0mDz8BW0phV1aeBt9MZEPZXOh+fv4nOTAHQCb7OAy4GLgEuaPaNpq2fAt9prnU+Dw9GJ9EZUHUDcCudIPONS7jGLcDuzbG30Ml07l5VN4+mT4td+1dVtaRs9GnAj+lMAfZnOlnuoWUGixafuCXJBctqpyn9+Abw8aq6qKr+QGdmhWMXzTghSY82cfCsJEmS2sCMrSRJklrBwFaSJEmtYGArSZKkrkuyUpJzklyU5LJmdUmSTEvy0yR/aL6uNeScw5JcneSqJDsvsw1rbCVJktRtzXLfq1bVXUlWAH4FvBV4CXBrVX0syaF0pkR8T5LN6cyqsz2d+cd/BmxWVUua7QYwYytJkqQJUB13NU9XaLYC9gSOafYfwz/mRd8TOK6q7mumU7yaTpC7VMOtFNRTK2/7JlPJGpVrz/xMr7ugAbTmKiv0uguSHoVWmvLQIi09Nx6x172/+59h30+SyXSmatwE+HxVnZ1kRlXNA6iqeUmmN4c/DvjtkNPn8vAVIh/BjK0kSZIgk8a8JZmd5Lwh2+yhTVTVwqraBlgf2D7JlsP1aAn7hg2++zZjK0mSpMFSVXOAOSM47rYkZwC7APOTrNdka9cDbmoOmwvMGnLa+ixjOXYztpIkSYJk7Nuwl8+6SR7TPF4ZeD5wJXAicGBz2IHAD5vHJwIHJFkxyROATYFzhmvDjK0kSZI65QTdtR5wTFNnOwk4vqp+lOQ3wPFJDgKuA/YDqKrLkhwPXA48ABw83IwIYGArSZIkWGbGdayq6mJg2yXsvwV43lLOORI4cqRtWIogSZKkVjBjK0mSpIkoReg6A1tJkiR1vRRhIhjYSpIkyYytJEmSWqIFGdvBD80lSZIkzNhKkiQJLEWQJElSS7SgFMHAVpIkSWZsJUmS1BItyNgOfmguSZIkYcZWkiRJYCmCJEmSWsLAVpIkSa0wyRpbSZIkqS+YsZUkSZKlCJIkSWqJFkz3ZWArSZIkM7aSJElqiRZkbAc/NJckSZIwYytJkiSwFEGSJEkt0YJSBANbSZIkmbGVJElSS7QgYzv4obkkSZKEGVtJkiSBpQiSJElqiRaUIhjYSpIkqRUZ28F/B5IkSRJmbCVJkgStyNga2PahFadO4WdHH8LUqVOYMnkyJ/zsd3zkS6ew1hqrcOzHX80Gj53Gn2+4lX9999Hcdue9TFtzVb71yYN4yhYb8I0Tf8vbPv7dXr8F9YH5N87jox94L7fccjOTMok99t6X/V72Sr7yxc/xq7N+zqRM4jHTpvHe9x/JOutO73V31cd+/cuz+PjHjuTBhQ+y9z77cdBrZ/e6SxoQ3jsDpgU1tqmqXvdhiVbe9k392bEJsurKU7n73vuZMmUSP//q23nnJ7/Hnjttzd/uuIdPfe2nvPNVL+Axq6/C4Z/9IausNJVtnrQ+m2/yWLbYeL1HfWB77Zmf6XUX+sLNN/+VW27+K0980ubcc/fdvObfXspHP/lZ1p0+g1VXWw2A7x33Da695o+887D397i3vbfmKiv0ugt9aeHChbx4t5358lFfY8aMGbx8/3352Cc/zcabbNLrrqnPee+MzEpT6JtocuU9vzzm2OveH76up++naznnJLsnLchp98jd994PwApTJjNlymSqit132IpvnHQ2AN846Wz22HErAO75+/38vwv/xN/vW9Cz/qr/rLPOujzxSZsDsMqqq7LBhhvx17/OfyioBfj7vfeSFvyFru659JKLmTVrA9afNYsVpk5ll11344xfnN7rbmkAeO8MoGTsW491M/A8APhDkk8k+acuttNKkyaF3x53KNed/jF+/tsrOffSPzN97dW58eY7ALjx5jtYd9rqPe6lBsW8G/7CH666gs236PwxdNQX/pt9dnsePz31ZA563Zt63Dv1s5vmz2fmejMfej59xgzmz5/fwx5pUHjvqBe6FthW1b8C2wJ/BL6W5DdJZidZajTWvH5ekvMeuPmybnVtIDz4YPG0Az7GJjsfznZbbsDmG6/X6y5pQN1zzz38x3vexpvf/p6HsrWvfeNb+f7Jp/OCXXbjB8d/q8c9VD8rHvnJpFl+jYT3zgDKpLFvPdbVHlTVHcD3geOA9YC9gQuSvHkpx8+pqu2qarsp62zRza4NjNvvupezzvsDL3zG5tx0y53MXGcNAGauswZ/vfXOHvdO/e6BBxbwH+85hBfsshvP3ekFj3j9+bvsxpk//1kPeqZBMWPGTG6cd+NDz2+aP5/p0x1sqGXz3hlAliIsXZI9kpwA/BxYAdi+ql4EbA28s1vttsE6a63GmqutDMBKK67ATv/yRK66dj4nn3kJ/7rHvwDwr3v8Cz864+JedlN9rqr4+IePYIMNN2L/Vxz40P7rr/vzQ49/fdYvePyGT+hF9zQgttjyyVx33bXMnXs9C+6/n1NPOZnn7rhTr7ulAeC9M3iSjHnrtW5O97Uf8JmqOmvozqq6J8mru9juwJu5zhoc9aFXMnnSJCZNCt//6QX8+JeXcvbF1/CNj7+aA/d6OtfP+xuvePfRD51z5ckfZPVVV2LqClPYY8et2P2Nn+fKP904TCtqu0su+h2nnXISG22yKa9++T4AvPbgt3LyD3/A9X++lkwKM2c+lnccdkSPe6p+NmXKFA573xG8YfZrePDBhey19z5sssmmve6WBoD3zuDph8B0rLo63VeSGcBTm6fnVNVNIz330T7dl0bP6b40Gk73JakX+mm6r1X3/dqYY6+7v/eq1k73tR9wDp3M7UuBs5Ps2632JEmSNAYZh63HulmKcDjw1EVZ2iTrAj8DvtfFNiVJkjQKbShF6GZgO2mx0oNb6PIsDJIkSRodA9vhnZrkNODbzfMDgB93sT1JkiQ9inUtsK2qdyV5CfBMOlUXX6qq/+tWe5IkSRo9M7ZLkOROeGi5kaHfodcm+TudlcjeV1UuGC1JktQn2hDYjnvNa1WtXlVrNNvqQzdgJvA64L/Hu11JkiSNQZdnRUgyK8kvklyR5LIkb232fyDJX5Jc2Gy7DjnnsCRXJ7kqyc7LegvdrLF9hKpaCFyU5HMT2a4kSZKGNwEZ2weAd1TVBUlWB85P8tPmtc9U1acW68/mdMZobQE8FvhZks2aeHKJejJLQVV9uRftSpIkqTeqal5VXdA8vhO4AnjcMKfsCRxXVfdV1TXA1cD2w7Xh9FuSJEkiyZi35WhrQ2Bb4Oxm15uSXJzkq0nWavY9Drh+yGlzGT4QNrCVJEnS+AS2SWYnOW/INnsJ7awGfB84pKruAL4IbAxsA8wD/nPRoUvo5rDL/k5oja0kSZL603jU2FbVHGDOMG2sQCeo/WZV/aA5Z/6Q148CftQ8nQvMGnL6+sANw7VvxlaSJEkTMStCgKOBK6rq00P2rzfksL2BS5vHJwIHJFkxyROATYFzhmvDjK0kSZImwjOBVwKXJLmw2fde4GVJtqFTZnAtnalhqarLkhwPXE5nRoWDh5sRAQxsJUmSRPen+6qqX7HkvO4pw5xzJHDkSNswsJUkSVIrVh4zsJUkSVIrAlsHj0mSJKkVzNhKkiRpmbMaDAIDW0mSJLWiFMHAVpIkSQa2kiRJaoc2BLYOHpMkSVIrmLGVJElSKzK2BraSJElyVgRJkiS1gxlbSZIktUIbAlsHj0mSJKkVzNhKkiSpFRlbA1tJkiQ5eEySJEnt0IaMrTW2kiRJagUztpIkSWpFxtbAVpIkSQa2kiRJagcDW0mSJLXD4Me1/RvY/vW3n+t1FzSg7n/gwV53QZIk9UDfBraSJEmaOJYiSJIkqRUMbCVJktQKLYhrXaBBkiRJ7WDGVpIkSZYiSJIkqR1aENca2EqSJMmMrSRJklqiBXGtg8ckSZLUDmZsJUmSxKRJg5+yNbCVJElSK0oRDGwlSZLk4DFJkiS1QwviWgePSZIkqR3M2EqSJMlSBEmSJLWDga0kSZJaoQVxrTW2kiRJagcztpIkSbIUQZIkSe3QgrjWwFaSJElmbCVJktQSLYhrHTwmSZKkdjBjK0mSpFaUIpixlSRJEsnYt+Gvn1lJfpHkiiSXJXlrs39akp8m+UPzda0h5xyW5OokVyXZeVnvwcBWkiRJJBnztgwPAO+oqn8CngYcnGRz4FDg9KraFDi9eU7z2gHAFsAuwBeSTB6uAQNbSZIkdT1jW1XzquqC5vGdwBXA44A9gWOaw44B9moe7wkcV1X3VdU1wNXA9sO1YWArSZKkcZFkdpLzhmyzl3LchsC2wNnAjKqaB53gF5jeHPY44Pohp81t9i2Vg8ckSZI0LoPHqmoOMGcZ7awGfB84pKruGKbdJb1Qw13bwFaSJEkTMo9tkhXoBLXfrKofNLvnJ1mvquYlWQ+4qdk/F5g15PT1gRuGu76lCJIkSer64LF0DjgauKKqPj3kpROBA5vHBwI/HLL/gCQrJnkCsClwznBtmLGVJEnSRHgm8ErgkiQXNvveC3wMOD7JQcB1wH4AVXVZkuOBy+nMqHBwVS0crgEDW0mSJHW9FKGqfsWS62YBnreUc44EjhxpGwa2kiRJasXKYwa2kiRJMrCVJElSO7QgrnVWhEFz5x138O63v4WXvPhF7LPnrlx80e963SX1qY984H3s+rxn8Yr9Xvyw/d897hvsv/euvHzfPfif//pUj3qnQfLrX57Fi3fbmd13eQFHHzXs9JTSw3jvaKKZsR0wn/z4kTz9mc/mE5/+LAsW3M/f7/17r7ukPrXbHnuz3/6v4ENHHPrQvvPPPZuzzvg5x37n/5g6dSq33npLD3uoQbBw4UI+euSH+PJRX2PGjBm8fP992WHHndh4k0163TX1Oe+dwdOGUoQJy9gmWSvJVhPVXhvddddd/O7889jrJfsCsMIKU1l9jTV63Cv1q22fsh1rrLnmw/b94HvH8cpXvYapU6cCMG3a2r3omgbIpZdczKxZG7D+rFmsMHUqu+y6G2f84vRed0sDwHtn8CRj33qtq4FtkjOSrJFkGnAR8LUkn17WeVqyv8y9nrWmTeMD/3EYL3/p3nzo/Ydz7z339LpbGiDX//laLrrgfA76t/15w2v+jcsvu6TXXVKfu2n+fGauN/Oh59NnzGD+/Pk97JEGhffO4On2Ag0TodsZ2zWr6g7gJcDXquopwPOXdnCS2UnOS3LeV79iLc7iFi58gCuvuJx9X/oyvnX8Cay88sp87atH9bpbGiALFy7kzjvv4CvHHMebDnknh7/n7VQNu+y2HuVqCcuy98MvL/U/753B04aMbbdrbKc0a/6+FHjfsg6uqjnAHIC77vO37eKmz5jJ9BkzePJWWwPw/BfsbGCr5bLu9JnssNMLSMIWW27FpEmTuO22v7HWWtN63TX1qRkzZnLjvBsfen7T/PlMnz69hz3SoPDeUS90O2P7IeA04OqqOjfJRsAfutxma62zzrrMmLEe117zJwDOOfs3bLTRxj3ulQbJc3bcifPOPRuA6/58LQsWLOAxj1mrx71SP9tiyydz3XXXMnfu9Sy4/35OPeVknrvjTr3ulgaA987gmZSMeeu19OvHkGZsl+yqK6/gwx84nAULFvC49WfxgQ9/lDXWWHPZJz6K3P/Ag73uQl844rB3csH553DbbbcxbdravOb1b+JFu+3BkR84nD/8/kqmrLACbz7kXWy3/dN63dW+sMqKk3vdhb71y7PO5BMf+ygPPriQvfbeh9e+7g297pIGhPfOsq00ZalLzE64F37+t2OOvX5y8NN6+n66Gtgm+QTwEeBe4FRga+CQqvrGss41sNVoGdhqNAxsJfVCPwW2O3/h7DHHXqe98V96+n66XYrwwmbw2O7AXGAz4F1dblOSJEmPQt0ePLZC83VX4NtVdasjIiVJkvrPpBaEaN0ObE9KciWdUoQ3JlkXcKksSZKkPtOG5GNXA9uqOjTJx4E7qmphknuAPbvZpiRJkpZfC+Larq88tgpwMPDFZtdjge262aYkSZKWX8bhv17r9uCxrwH3A89ons+lM0uCJEmSNK66HdhuXFWfABYAVNW90AfhvCRJkh5mUsa+9Vq3B4/dn2Rl6CwYnWRj4L4utylJkqTl5OCxZXs/nYUZZiX5JvBM4N+73KYkSZKWUwvi2q7PivDTJBcAT6NTgvDWqrq5m21KkiRp+U1qQWTb7YwtwErA35q2Nk9CVZ01Ae1KkiTpUaSrgW0zh+3+wGXAg83uAgxsJUmS+kgLErZdz9juBTyxqhwwJkmS1MccPLZsfwJWwJkQJEmS+loL4tquB7b3ABcmOZ0hwW1VvaXL7UqSJOlRptuB7YnNJkmSpD7mrAjLUFXHdPP6kiRJGh+DH9Z2KbBNcgnNamNLUlVbdaNdSZIkjY6Dx5Zu9+brwc3XY5uvr6BTdytJkqQ+Mmnw49ruBLZV9WeAJM+sqmcOeenQJL8GPtSNdiVJkvToNanL1181ybMWPUnyDGDVLrcpSZKk5ZRkzFuvdXtWhIOAryZZs3l+G/DqLrcpSZKk5dQHcemYdXtWhPOBrZOsAaSqbu9me5IkSRqdfsi4jtVSA9skn2P4mQ1GtMhCkt2ALYCVFn3DqsoaW0mSpD7S9sFj54314km+BKwC7Ah8BdgXOGes15UkSZIWt9TAdpwWV3hGVW2V5OKq+mCS/wR+MA7XlSRJ0jhqdSnCIknWBd4DbA6stGh/Ve00guvf23y9J8ljgVuBJ4yin5IkSeqiwQ9rRzbd1zeBK+gEpB8ErgXOHeH1f5TkMcAngPOBa4DjlruXkiRJ6qpJyZi3XhtJYLt2VR0NLKiqM6vq1cDThjshyVOTzKyqD1fVbcBqwCXAd4HPjLXTkiRJ0uJGEtguaL7OS7Jbkm2B9ZdxzpeB+wGSPAf4WLPvdmDOKPsqSZKkLknGvvXaSOax/UizwMI7gM8BawBvW8Y5k6vq1ubx/sCcqvo+8P0kF462s5IkSeqOR8Xgsar6UfPwdjrTdo3E5CRTquoB4HnA7OVpU5IkSROrBXHtiGZF+BpLWKihqbVdmm8DZya5mc7MCL9srrUJnQBZkiRJfaQfBn+N1UhqbH8EnNxsp9MpRbhruBOq6kg6pQtfB55VVYsC40nAm0fbWUmSJA2uJF9NclOSS4fs+0CSvyS5sNl2HfLaYUmuTnJVkp2Xdf2RlCJ8f7EOfRv42QjO++0S9v1+WedJkiRp4k1QwvbrwP8A/7vY/s9U1ace3p9sDhwAbAE8FvhZks2qauHSLj6aetdNgceP4rzlMrkNCxarJ1ZZcXKvuyBJ0sCZiMFjVXVWkg1HePiewHFVdR9wTZKrge2B3yzthGWWIiS5M8kdizbgJDorkUmSJKklJo3DlmR2kvOGbLMf0dCSvSnJxU2pwlrNvscB1w85Zm6zb6lGUoqw+gg7JEmSpAE1HhnbqprD8q9Z8EXgw3QmK/gw8J/Aq1nyKr+PmNBgqJFkbE8fyT5JkiRpeVXV/KpaWFUPAkfRKTeAToZ21pBD1wduGO5aSw1sk6yUZBqwTpK1kkxrtg3pFPBKkiSpJSZl7NtoJFlvyNO9gUUzJpwIHJBkxSRPoDPO65zhrjVcKcLrgEPoBLHn84908B3A55e/25IkSepXEzFuv5ldawc6idO5wPuBHZJsQ6fM4Fo6MShVdVmS44HLgQeAg4ebEQEg/5hidqkdeHNVfW5sb2P53btg+BoKaWlaML+0JOlRYqUpS6wj7Yl3nHTVmGOv/9zjiT19PyNZoOHBJI9Z9KQpS3hj97okSZIkLb+RBLavrarbFj2pqr8Br+1ajyRJkjThelVjO55GskDDpCRZtCxuksnA1O52S5IkSROpDaV8IwlsTwOOT/IlOkW9rwd+3NVeSZIkaUJNakFkO5LA9j3AbOANdGZG+B2w3rBnSJIkaaCMpD613y3zPTST5f4W+BOwHfA84Iou90uSJElaLkvN2CbZDDgAeBlwC/AdgKracWK6JkmSpInSgkqEYUsRrgR+CexRVVcDJHnbhPRKkiRJE6oNNbbDlSLsA9wI/CLJUUmeB/0zibAkSZLGTzL2rdeWGthW1QlVtT/wJOAM4G3AjCRfTPLCCeqfJEmSNCIjGTx2d1V9s6p2B9YHLgQO7XbHJEmSNHEeLQs0PKSqbgW+3GySJElqiTbU2C5XYCtJkqR2akFca2ArSZKk/iglGKs2LDIhSZIkmbGVJEkSpAWzuhrYSpIkqRWlCAa2kiRJMrCVJElSO6QF0yI4eEySJEmtYMZWkiRJliJIkiSpHVpQiWBgK0mSpHYsqWuNrSRJklrBjK0kSZKssZUkSVI7tKASwcBWkiRJMMkldSVJktQGbcjYOnhMkiRJrWDGVpIkSa0YPGbGdoDcOG8er3nVK9l7jxfxkj1345vHHtPrLmmA/PqXZ/Hi3XZm911ewNFHzel1dzRAvHc0Wt47g2VSMuat18zYDpDJUybzjncdyj9tvgV3330XL3vpPjztGc9k44036XXX1OcWLlzIR4/8EF8+6mvMmDGDl++/LzvsuBMbb+K9o+F572i0vHcGTx/EpWNmxnaArLvudP5p8y0AWHXV1dhoo424af78HvdKg+DSSy5m1qwNWH/WLFaYOpVddt2NM35xeq+7pQHgvaPR8t4ZPG3I2HYtsE0yOcknu3X9R7u//GUuV15xBU/eauted0UD4Kb585m53syHnk+fMYP5/lGkEfDe0Wh576gXuhbYVtVC4CnJyMP3JLOTnJfkvKO/Yi3O0txzz928821v4V3veS+rrbZar7ujAVDUI/Ytxz9NPYp572i0vHcGTzL2rde6XWP7O+CHSb4L3L1oZ1X9YEkHV9UcYA7AvQuW8C9CLFiwgHcc8hZ23W0PnveCF/a6OxoQM2bM5MZ5Nz70/Kb585k+fXoPe6RB4b2j0fLeGTxtqE/t9nuYBtwC7ATs0Wy7d7nN1qoqPnjE+3jCRhvxygNf1evuaIBsseWTue66a5k793oW3H8/p55yMs/dcaded0sDwHtHo+W9M3iSjHnrta5mbKvK6GscXfi78/nRST9k000346X77AnAm9/6dp79nOf2uGfqd1OmTOGw9x3BG2a/hgcfXMhee+/DJpts2utuaQB472i0vHfUC6nq3if+SVYCDgK2AFZatL+qXr2scy1F0Gj1wR+MkiSNyEpT6JvfWv973vVjjr3+bbtZPX0/3S5FOBaYCewMnAmsD9zZ5TYlSZK0nJzua9k2qar/AO6uqmOA3YAnd7lNSZIkLaeMw9Zr3Z4VYUHz9bYkWwI3Aht2uU1JkiQtpz5IuI5ZtwPbOUnWAv4DOBFYDTiiy21KkiTpUajbsyJ8pXl4JrBRN9uSJEnS6PXDdF1j1dUa2yQzkhyd5MfN882THNTNNiVJkrT8Jo3D1mvd7sPXgdOAxzbPfw8c0uU2JUmStJwmYoGGJF9NclOSS4fsm5bkp0n+0Hxda8hrhyW5OslVSXZe1vW7HdiuU1XHAw8CVNUDwMIutylJkqTlNEGzInwd2GWxfYcCp1fVpsDpzXOSbA4cQGc9hF2ALySZPNzFux3Y3p1kbegstpDkacDtXW5TkiRJfaiqzgJuXWz3nsAxzeNjgL2G7D+uqu6rqmuAq4Hth7t+t2dFeDud2RA2TvJrYF1g3y63KUmSpOU0HoPHkswGZg/ZNaeq5izjtBlVNQ+gquYlmd7sfxzw2yHHzW32LVVXAtskj6+q66rqgiTPBZ5IJ0N9VVUtWMbpkiRJmmDj8TF+E8QuK5AdqSVF2sMu+9utUoT/G/L4O1V1WVVdalArSZLUnyZi8NhSzE+yXtOH9YCbmv1zgVlDjlsfuGG4C3UrsB36zpy/VpIkSUtzInBg8/hA4IdD9h+QZMUkTwA2Bc4Z7kLdqrGtpTyWJElSH5qI5RmSfBvYAVgnyVzg/cDHgOObtQ6uA/YDqKrLkhwPXA48ABxcVcPOrpWq8Y87kywE7qbzPVoZuGfRS51+1hrLusa9CwyINTotWDhFkvQosdKUCYknR+SHl9w45thrzyfP7On76UrGtqqGnWNMkiRJ/WVS/8TYo9bt6b4kSZI0ANrwiWc/LOsrSZIkjZkZW0mSJBFLESRJktQGbShFMLCVJEmSg8ckSZLUDm3I2Dp4TJIkSa1gxlaSJEmtyNga2EqSJMlZESRJktQOkwY/rrXGVpIkSe1gxlaSJEmWIkiSJKkdHDwmSZKkVjBjK0mSpFZw8JgkSZLUJ8zYSpIkyVIESZIktYODxyRJktQKLYhrDWwlSZIEk1qQsu3bwLYF31v1SFWve6BB5M8cSRp8fRvYSpIkaeK04e97A1tJkiS1IrI1sJUkSVIrpvtygQZJkiS1ghlbSZIktWIQrYGtJEmSWlCIYGArSZIkaEVka2ArSZIkB49JkiRJ/cKMrSRJkhw8JkmSpHZoQVxrYCtJkiRaEdka2EqSJMnBY5IkSVK/MGMrSZIkB49JkiSpHVoQ1xrYSpIkiVZEttbYSpIkqRXM2EqSJKkVsyIY2EqSJMnBY5IkSWqHFsS1BraSJEmiFZGtg8ckSZLUCmZsJUmSNCGDx5JcC9wJLAQeqKrtkkwDvgNsCFwLvLSq/jaa65uxlSRJEsnYtxHasaq2qartmueHAqdX1abA6c3zUTGwlSRJEhmHbZT2BI5pHh8D7DXaCxnYSpIkaaIU8JMk5yeZ3eybUVXzAJqv00d7cWtsJUmSNC6zIjTB6uwhu+ZU1Zwhz59ZVTckmQ78NMmVY2/1HwxsJUmSNC6Dx5ogds4wr9/QfL0pyQnA9sD8JOtV1bwk6wE3jbZ9SxEkSZLU9cFjSVZNsvqix8ALgUuBE4EDm8MOBH442vdgxlaSJEkTsT7DDOCEdCLgKcC3qurUJOcCxyc5CLgO2G+0DRjYSpIkqeuq6k/A1kvYfwvwvPFow8BWkiRJrVhS18BWkiRJE7LyWLcZ2EqSJGl5Vg7rWwa2kiRJakG+1um+Bs4Rhx/GDs9+Oi/Zc/ded0UD5MZ583jNq17J3nu8iJfsuRvfPPaYZZ8kNX79y7N48W47s/suL+Doo5Y6PaX0CN47mmgGtgNmz71ewhe//JVed0MDZvKUybzjXYdywkk/5thvfYfvHPct/vjHq3vdLQ2AhQsX8tEjP8QXvvQVTjjxZE495Uf88WrvHS2b984AyjhsPdaVwDbJ5CQ/68a1H+2est1TWWPNNXvdDQ2Yddedzj9tvgUAq666GhtttBE3zZ/f415pEFx6ycXMmrUB68+axQpTp7LLrrtxxi9O73W3NAC8dwZPxuG/XutKYFtVC4F7khiBSX3mL3+Zy5VXXMGTt3rEVILSI9w0fz4z15v50PPpM2Yw3z+KNALeO4On2yuPTYRuliL8HbgkydFJPrtoG+6EJLOTnJfkPGtxpPF3zz138863vYV3vee9rLbaar3ujgZAUY/Yl3747aW+572jXujmrAgnN9uIVdUcYA7A3x9Ywr8ISaO2YMEC3nHIW9h1tz143gte2OvuaEDMmDGTG+fd+NDzm+bPZ/r06T3skQaF987gacOfHV3L2FbVMcDxwG+r6phFW7fak7R0VcUHj3gfT9hoI1554Kt63R0NkC22fDLXXXctc+dez4L77+fUU07muTvu1OtuaQB47wygFgweS1V3EqNJ9gA+BUytqick2Qb4UFW9eCTnm7Fdsve88+2cd+453Hbb35i29tq84eA385J99ut1t/pKl27pgfa7C87jVf/2CjbddDMyqfP37Jvf+nae/Zzn9rhn/cNPSJful2edySc+9lEefHAhe+29D6993Rt63SUNCO+dZVtpSj+Egx1/vuW+Mf8G3WDtFXv6froZ2J4P7AScUVXbNvsuqaonj+R8A1uNloGtRsPAVlIv9FNge92tYw9sHz+tt4FtNwePPVBVty+2z5BDkiRJXdHNwWOXJnk5MDnJpsBbgP/XxfYkSZI0Sn2TOh6DbmZs3wxsAdwHfBu4Aziki+1JkiRplNowj23XamzHyhpbjVaf3tLqc/3wA1nSo08/1djO/dv9Y/4Nuv5aU3v6frpWipDkJB5ZU3s7cB7w5ar6e7faliRJ0vJpwx/43SxF+BNwF3BUs90BzAc2a55LkiRJ46abg8e2rarnDHl+UpKzquo5SS7rYruSJElaTi1I2HY1Y7tukscvetI8Xqd5en8X25UkSdJyasPgsW5mbN8B/CrJH+n8EfAE4I1JVgVcWleSJKmPpAU5267OipBkReBJdALbK5dnwJizImi0nBVBo9EPmQZJjz79NCvCjbcvGPNv0JlrrtDOWREaTwE2bNrZKglV9b9dblOSJEnLq29C7NHr5nRfxwIbAxcCC5vdBRjYSpIk9ZkWxLVdzdhuB2xe/boChCRJkh7ShpKsbga2lwIzgXldbEOSJEnjoA2Dx7oZ2K4DXJ7kHOC+Zl9V1Z5dbFOSJEmPUt0MbD8w5HGAZwEv62J7kiRJGq3BT9h2L7CtqjOTbAO8HHgpcA3wpW61J0mSpNFrQVw7/oFtks2AA+hkZ28BvkNnvtwdx7stSZIkjQ8Hjy3ZlcAvgT2q6mqAJG/rQjuSJEkaJ20YPDapC9fcB7gR+EWSo5I8j3ZktyVJktTHurakbpJVgb3olCTsBBwDnFBVPxnJ+S6pq9Fy5mSNRhs+gpM0ePppSd2/3bNwzL9B11plck/fT9cC24c1kkwD9gP2r6qdRnKOga1Gy8BWo2FgK6kXDGzH14QEtqNhYKvR6tNbWn3OwFZSL/RTYHvbvWMPbB+zcm8D227U2EqSJEkTrpsLNEiSJGlAtGFWBANbSZIktaIky8BWkiRJLcjXGthKkiQJWhHZOnhMkiRJrWDGVpIkSQ4ekyRJUjs4eEySJEmt0IK41hpbSZIk0Ylsx7otq4lklyRXJbk6yaHj/RYMbCVJktR1SSYDnwdeBGwOvCzJ5uPZhoGtJEmSyDj8twzbA1dX1Z+q6n7gOGDP8XwP1thKkiRpIgaPPQ64fsjzucC/jGcDfRvYrjSlFTXMXZNkdlXN6XU/NFi8bzRa3jsaLe+dwTEesVeS2cDsIbvmDPn/v6Tr11jbHMpShME1e9mHSI/gfaPR8t7RaHnvPIpU1Zyq2m7INvSPmrnArCHP1wduGM/2DWwlSZI0Ec4FNk3yhCRTgQOAE8ezgb4tRZAkSVJ7VNUDSd4EnAZMBr5aVZeNZxsGtoPLeiWNhveNRst7R6PlvaOHVNUpwCndun6qxrVmV5IkSeoJa2wlSZLUCga2fS7JXb3ug3oryfuSXJbk4iQXJhnRnH9JNkxyabf7p8GXZGFzby3aNux1n9SfkuydpJI8qdd9kZbEGlupjyV5OrA78M9VdV+SdYCpPe6W2ufeqtpmvC6WZEpVPTBe11NfeRnwKzqj2T/QrUa8hzRaZmwHQDo+meTSJJck2b/Zf2ySPYcc980kL+5dT9UF6wE3V9V9AFV1c1XdkOSIJOc298ScpLNeTJKnJLkoyW+AgxddJMm/J/lBklOT/CHJJ4a89sIkv0lyQZLvJlmt2f+xJJc3meJPNfv2a9q8KMlZE/mN0MRq7qUzk5yf5LQk6zX7X9vcexcl+X6SVZr9X0/y6SS/AD7e086rK5qfDc8EDqIT2JJkhyRnJPlekiub30OLfh7t2uz7VZLPJvlRs3/VJF9t7qPfLfo91vyc+m6Sk4Cf9OZdatAZ2A6GlwDbAFsDzwc+2fyS+QrwKoAkawLPoIsjDdUTPwFmJfl9ki8keW6z/3+q6qlVtSWwMp2sLsDXgLdU1dOXcK1tgP2BJwP7J5nVZIAPB55fVf8MnAe8Pck0YG9gi6raCvhIc40jgJ2ramvAP6LaY+UhZQgnJFkB+Bywb1U9BfgqcGRz7A+ae29r4Ao6Qc4im9G5l94xob3XRNkLOLWqfg/cmuSfm/3bAocAmwMbAc9MshLwZeBFVfUsYN0h13kf8POqeiqwI53faas2rz0dOLCqdur2m1E7WYowGJ4FfLuqFgLzk5wJPLWqTkzy+STT6QS/3/ejm3apqruSPAV4Np1fAN9JcihwZ5J3A6sA04DLmgzqY6rqzOb0Y4EXDbnc6VV1O0CSy4ENgMfQ+WX06ybJMhX4DXAH8HfgK0lOBn7UXOPXwNeTHA/8oDvvWj3wsFKEJFsCWwI/be6LycC85uUtk3yEzr2zGp35KBf5bvNzSu30MuC/msfHNc9PBs6pqrkASS4ENgTuAv5UVdc0x3+bf6xA9kLgxUne2TxfCXh88/inVXVr996C2s7AdjAMt3bzscAr6Hws9OqJ6Y4mUhMonAGckeQS4HXAVsB2VXV9kg/Q+cUQhl9z+74hjxfS+fcfOr9IXrb4wUm2B55H5956E7BTVb2+Gby2G3Bhkm2q6pYxvkX1nwCXLSXz/3Vgr6q6KMm/AzsMee3u7ndNvZBkbWAnOn/YFJ0/dorOp4RL+9my1MsB+1TVVYu18S94D2mMLEUYDGfR+eh4cpJ1gecA5zSvfZ3OR0CM9+od6r0kT0yy6ZBd2wCLfhnc3NS87QtQVbcBtyd5VvP6K0bQxG/pfGy4SdPeKkk2a667ZjOR9iFNuyTZuKrOrqojgJt5+Jrfao+rgHXTGbxIkhWSbNG8tjowrylXGMk9pnbYF/jfqtqgqjasqlnANXQ+UVySK4GN8o8ZNvYf8tppwJuH1OJu26U+61HIjG0fSzKFzl/CJ9CpO7qIzl/I766qGwGqan6SK4D/61U/1VWrAZ9L8hjgAeBqOh/n3QZcAlxLZ+3tRV4FfDXJPTz8I+Ilqqq/Nlm3bydZsdl9OHAn8MOmTi7A25rXPtkE2gFOp3NPqmWq6v4k+wKfber3p9D5CPoy4D+As4E/07kHV+9VPzWhXgZ8bLF93wfeAPxx8YOr6t4kbwROTXIz/0jGAHyYzv10cRPcXss/xglIY+LKY30sydbAUVW1/TDHrELnl8s/L6qflCSp15Ks1owTCPB54A9V9Zle90vtZilCn0ryejrF9ocPc8zz6Xzc8zmDWklSn3ltM5jsMmBNOrMkSF1lxlaSJEmtYMZWkiRJrWBgK0mSpFYwsJUkSVIrGNhKGihJFjZLv17arCu/yhiu9fVmWiuSfCXJ5sMcu0OSZ4yijWubpYslSV1mYCtp0NxbVdtU1ZbA/cDrh76YZPJoLlpVr6mqy4c5ZAdguQNbSdLEMbCVNMh+CWzSZFN/keRbwCXNKn2fTHJukouTvA4gHf+T5PIkJwPTF10oyRlJtmse75LkgiQXJTm9WT3p9cDbmmzxs5Osm+T7TRvnJnlmc+7aSX6S5HdJvszwS4tKksaRK49JGkjNynwvAk5tdm0PbFlV1ySZDdxeVU9tVlT7dZKfANsCTwSeDMwALge+uth11wWOAp7TXGtaVd2a5EvAXVX1qea4bwGfqapfJXk8nZXe/gl4P/CrqvpQkt3orBQnSZoABraSBs3KzaTv0MnYHk2nROCcqrqm2f9CYKtF9bN0JoffFHgO8O2qWgjckOTnS7j+04CzFl2rqm5dSj+eD2zeLHcPsEaS1Zs2XtKce3KSv43ubUqSlpeBraRBc29VbTN0RxNc3j10F/DmqjptseN2BZa1Kk1GcAx0SrmeXlX3LqEvrnwjST1gja2kNjoNeEOSFQCSbJZkVeAs4ICmBnc9YMclnPsb4LlJntCcO63Zfyew+pDjfgK8adGTJNs0D88CXtHsexGw1ni9KUnS8AxsJbXRV+jUz16Q5FI6a9RPAU4A/gBcAnwROHPxE6vqr3TqYn+Q5CLgO81LJwF7Lxo8BrwF2K4ZnHY5/5id4YPAc5JcQKck4rouvUdJ0mJS5SdmkiRJGnxmbCVJktQKBraSJElqBQNbSZIktYKBrSRJklrBwFaSJEmtYGArSZKkVjCwlSRJUisY2EqSJKkV/j+G/wBcU5QDyAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Classification report\\n\", classification_report(actual_classes, predicted_classes))\n",
    "print(f\"Accuracy: {accuracy_score(actual_classes, predicted_classes)}\")\n",
    "plot_confusion_matrix(actual_classes, predicted_classes, EMOTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "1. Convert the predicted emotion codes back to textual emotions with a nice lambda function.\n",
    "2. Append the predicted emotions and predicted probabilities into the clean data.\n",
    "3. Take a look and see what the results look like.\n",
    "4. Apply the results to all 23,000 rows (after removing the nulls).\n",
    "\n",
    "Voila!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABETICAL_EMOTION_MAP : dict = {\n",
    "                                  'Anger': 0,\n",
    "                                  'Fear': 1,\n",
    "                                  'Joy': 2,\n",
    "                                  'Sadness': 3\n",
    "                                  }\n",
    "\n",
    "first_index = np.arange(len(predicted_classes))\n",
    "second_index = pd.Series(predicted_classes).map(ALPHABETICAL_EMOTION_MAP).to_numpy()\n",
    "    \n",
    "associated_proba = predicted_proba[first_index, second_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_val[\"Predicted Emotion\"] = predicted_classes\n",
    "df_reviews_val[\"Predicted Emotion Score\"] = associated_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion Score</th>\n",
       "      <th>Predicted Emotion</th>\n",
       "      <th>Predicted Emotion Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.796461</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.868333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.702502</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.671066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.855898</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.519885</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.472960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.664518</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.888750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.615711</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.542575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.615737</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.742984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.686012</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anger</td>\n",
       "      <td>0.541525</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.612050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.738641</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.856177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.738616</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.611057</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.914040</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.967723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.669543</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.724357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.721861</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.640576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.781762</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.594927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.528196</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.538333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.639846</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.509012</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.756880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.766350</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.873083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.539962</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.618608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.542410</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.892573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.706608</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.631748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.625392</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.795417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.665774</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.726316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.564748</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.762307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.507898</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.679159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.673157</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.812917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.703431</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.734468</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.548555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.585235</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.788823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.673789</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.981515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.788483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.870386</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.758714</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.822083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.839497</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.934378</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.991250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.613022</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.626862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.673071</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.716734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.707565</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.950417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.817867</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.594997</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.636488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.621420</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.680265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.683308</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.721674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.726155</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.645316</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.924882</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.978750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Joy</td>\n",
       "      <td>0.663089</td>\n",
       "      <td>Joy</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion  Emotion Score Predicted Emotion  Predicted Emotion Score\n",
       "0       Joy       0.796461               Joy                 0.868333\n",
       "1       Joy       0.702502               Joy                 0.671066\n",
       "2       Joy       0.855898               Joy                 0.832500\n",
       "3   Sadness       0.519885           Sadness                 0.472960\n",
       "4       Joy       0.664518               Joy                 0.888750\n",
       "5       Joy       0.615711               Joy                 0.542575\n",
       "6       Joy       0.615737               Joy                 0.742984\n",
       "7       Joy       0.686012               Joy                 0.843750\n",
       "8     Anger       0.541525           Sadness                 0.612050\n",
       "9       Joy       0.738641               Joy                 0.856177\n",
       "10      Joy       0.738616               Joy                 0.965000\n",
       "11      Joy       0.611057               Joy                 0.586667\n",
       "12      Joy       0.914040               Joy                 0.967723\n",
       "13      Joy       0.669543               Joy                 0.724357\n",
       "14      Joy       0.721861               Joy                 0.640576\n",
       "15      Joy       0.781762               Joy                 0.594927\n",
       "16      Joy       0.528196               Joy                 0.538333\n",
       "17      Joy       0.639846               Joy                 0.857500\n",
       "18      Joy       0.509012               Joy                 0.756880\n",
       "19      Joy       0.766350               Joy                 0.873083\n",
       "20      Joy       0.539962           Sadness                 0.618608\n",
       "21      Joy       0.542410               Joy                 0.892573\n",
       "22      Joy       0.706608               Joy                 0.631748\n",
       "23      Joy       0.625392               Joy                 0.795417\n",
       "24      Joy       0.665774               Joy                 0.726316\n",
       "25      Joy       0.564748               Joy                 0.762307\n",
       "26      Joy       0.507898               Joy                 0.679159\n",
       "27      Joy       0.673157               Joy                 0.795000\n",
       "28      Joy       0.710300               Joy                 0.812917\n",
       "29      Joy       0.703431               Joy                 0.926667\n",
       "30      Joy       0.734468               Joy                 0.548555\n",
       "31      Joy       0.585235               Joy                 0.788823\n",
       "32      Joy       0.792627               Joy                 0.955000\n",
       "33      Joy       0.673789               Joy                 0.981515\n",
       "34      Joy       0.675349               Joy                 0.788483\n",
       "35      Joy       0.870386               Joy                 0.965000\n",
       "36      Joy       0.758714               Joy                 0.822083\n",
       "37      Joy       0.839497               Joy                 0.977500\n",
       "38      Joy       0.934378               Joy                 0.991250\n",
       "39      Joy       0.613022           Sadness                 0.626862\n",
       "40      Joy       0.673071               Joy                 0.716734\n",
       "41      Joy       0.707565               Joy                 0.950417\n",
       "42      Joy       0.817867               Joy                 0.893333\n",
       "43  Sadness       0.594997           Sadness                 0.636488\n",
       "44      Joy       0.621420               Joy                 0.680265\n",
       "45      Joy       0.683308               Joy                 0.721674\n",
       "46      Joy       0.726155               Joy                 0.842500\n",
       "47  Sadness       0.645316           Sadness                 0.573333\n",
       "48      Joy       0.924882               Joy                 0.978750\n",
       "49      Joy       0.663089               Joy                 0.946667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_val[['Emotion', 'Emotion Score', 'Predicted Emotion', 'Predicted Emotion Score']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply our new emotional tone analyzer to the full dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_reviews_prod = pd.read_excel(f\"{DATA_IN_FOLDER}{SOURCE_FULL_DATA_FILE}\") # Read in the full source data file with 23k rows\n",
    "\n",
    "model = load_object(f\"{DATA_OUT_FOLDER}{MODEL_FILE}\") # Load the machine learning model from persistent storage\n",
    "tfidf_vectorizer = load_object(f\"{DATA_OUT_FOLDER}{VECTORIZER_FILE}\") # Load the word vectoriaing transformer from persistent storage\n",
    "\n",
    "tfidf_features = tfidf_vectorizer.transform(df_reviews_prod['Review Text Wordcloud']).toarray() # Predict the vectorized words from the word cloud\n",
    "\n",
    "X_prod = pd.concat([df_reviews_prod.iloc[:,[3,5]], pd.DataFrame(tfidf_features)], axis=1) # Create the input features to the model as source data features 3 and 5 and the vectorized features\n",
    "\n",
    "predicted_classes = model.predict(X_prod) # Predict the classes (emotional tones) for the full dataset\n",
    "predicted_proba = model.predict_proba(X_prod) # Predcit the probabilities (of membership of each of the four classes) for the full dataset\n",
    "\n",
    "# Extract the associated probability of the predicted class from predicted_proba\n",
    "first_index = np.arange(len(predicted_classes))\n",
    "second_index = pd.Series(predicted_classes).map(ALPHABETICAL_EMOTION_MAP).to_numpy()\n",
    "associated_proba = predicted_proba[first_index, second_index]\n",
    "\n",
    "df_reviews_prod['Emotion'] = predicted_classes # Update the target data with the predicted emotions\n",
    "df_reviews_prod['Emotion Score'] = associated_proba # Update the target data with the associated probabilities (emotion scores)\n",
    "\n",
    "df_reviews_prod.to_excel(f\"{DATA_OUT_FOLDER}{TARGET_FULL_DATA_FILE}\", index=False, sheet_name=\"reviews\") # Write the transformed data to a new Excel spreadsheet (preserving the original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joy        0.7940\n",
       "NaN        0.1235\n",
       "Sadness    0.0685\n",
       "Anger      0.0075\n",
       "Fear       0.0065\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_raw['Emotion'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joy        0.863239\n",
       "Sadness    0.135490\n",
       "Anger      0.000712\n",
       "Fear       0.000559\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_prod['Emotion'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/dont-just-fit-data-gain-insights-too-1dba73d3cf8e\n",
    "\n",
    "https://grahamharrison-86487.medium.com/membership"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
