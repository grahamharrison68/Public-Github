{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE : int = 42\n",
    "N_SAMPLES : int = 10000\n",
    "N_FEATURES : int = 25\n",
    "N_CLASSES : int = 3\n",
    "N_CLUSTERS_PER_CLASS : int = 2\n",
    "    \n",
    "FEATURE_NAME_PREFIX : str = \"Feature\"\n",
    "TARGET_NAME : str = \"Target\"\n",
    "    \n",
    "N_SPLITS : int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_informative=(N_CLASSES * N_CLUSTERS_PER_CLASS), random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_dataframe(n_samples : int = 10000, n_features : int = 25, n_classes : int = 2, n_clusters_per_class : int = 2, feature_name_prefix : str = \"Feature\", target_name : str = \"Target\", random_state : int = 42) -> pd.DataFrame:\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative = n_classes * n_clusters_per_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    feature_names = [feature_name_prefix + \" \" + str(v) for v in np.arange(1, N_FEATURES+1)]\n",
    "    return pd.concat([pd.DataFrame(X, columns=feature_names), pd.DataFrame(y, columns=[target_name])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 17</th>\n",
       "      <th>Feature 18</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature 24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.131637</td>\n",
       "      <td>2.281512</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.707735</td>\n",
       "      <td>1.628051</td>\n",
       "      <td>0.622273</td>\n",
       "      <td>-0.434003</td>\n",
       "      <td>-0.992722</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>-1.764985</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.673779</td>\n",
       "      <td>0.276305</td>\n",
       "      <td>-1.685462</td>\n",
       "      <td>-0.801336</td>\n",
       "      <td>0.806151</td>\n",
       "      <td>0.369108</td>\n",
       "      <td>-0.843748</td>\n",
       "      <td>0.966868</td>\n",
       "      <td>-0.547149</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.231544</td>\n",
       "      <td>-1.580880</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>-0.343771</td>\n",
       "      <td>0.498176</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.859592</td>\n",
       "      <td>-0.666477</td>\n",
       "      <td>-0.832989</td>\n",
       "      <td>-0.287655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341136</td>\n",
       "      <td>1.116596</td>\n",
       "      <td>1.134896</td>\n",
       "      <td>1.232907</td>\n",
       "      <td>1.295312</td>\n",
       "      <td>-0.253926</td>\n",
       "      <td>-0.528711</td>\n",
       "      <td>0.502124</td>\n",
       "      <td>0.896065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.301585</td>\n",
       "      <td>-1.922563</td>\n",
       "      <td>-0.623878</td>\n",
       "      <td>-0.740534</td>\n",
       "      <td>-0.723667</td>\n",
       "      <td>1.484827</td>\n",
       "      <td>1.227018</td>\n",
       "      <td>-0.050878</td>\n",
       "      <td>0.164059</td>\n",
       "      <td>0.301672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900290</td>\n",
       "      <td>0.682905</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>-0.023550</td>\n",
       "      <td>0.932216</td>\n",
       "      <td>0.109495</td>\n",
       "      <td>0.500366</td>\n",
       "      <td>0.956182</td>\n",
       "      <td>-2.268742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.899385</td>\n",
       "      <td>0.991619</td>\n",
       "      <td>0.494529</td>\n",
       "      <td>-0.672954</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>-0.271674</td>\n",
       "      <td>1.245351</td>\n",
       "      <td>0.146567</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>1.479558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285753</td>\n",
       "      <td>-1.446158</td>\n",
       "      <td>-0.062296</td>\n",
       "      <td>0.583408</td>\n",
       "      <td>1.588965</td>\n",
       "      <td>0.412651</td>\n",
       "      <td>-1.891714</td>\n",
       "      <td>-0.575163</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.026721</td>\n",
       "      <td>0.745777</td>\n",
       "      <td>0.188450</td>\n",
       "      <td>-0.794256</td>\n",
       "      <td>1.402570</td>\n",
       "      <td>1.057481</td>\n",
       "      <td>0.454773</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>-0.403872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959229</td>\n",
       "      <td>-1.964891</td>\n",
       "      <td>-0.296422</td>\n",
       "      <td>-0.755737</td>\n",
       "      <td>-0.489769</td>\n",
       "      <td>0.516726</td>\n",
       "      <td>-4.807225</td>\n",
       "      <td>1.215506</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0  -0.131637   2.281512   0.468810   0.707735   1.628051   0.622273   \n",
       "1  -1.231544  -1.580880   0.684543  -0.343771   0.498176  -0.008396   \n",
       "2  -1.301585  -1.922563  -0.623878  -0.740534  -0.723667   1.484827   \n",
       "3  -0.899385   0.991619   0.494529  -0.672954   0.421605  -0.271674   \n",
       "4  -3.026721   0.745777   0.188450  -0.794256   1.402570   1.057481   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 17  Feature 18  \\\n",
       "0  -0.434003  -0.992722   0.053795   -1.764985  ...   -1.673779    0.276305   \n",
       "1  -0.859592  -0.666477  -0.832989   -0.287655  ...    0.341136    1.116596   \n",
       "2   1.227018  -0.050878   0.164059    0.301672  ...   -0.900290    0.682905   \n",
       "3   1.245351   0.146567   0.389313    1.479558  ...   -0.285753   -1.446158   \n",
       "4   0.454773  -0.174391   0.951417   -0.403872  ...    0.959229   -1.964891   \n",
       "\n",
       "   Feature 19  Feature 20  Feature 21  Feature 22  Feature 23  Feature 24  \\\n",
       "0   -1.685462   -0.801336    0.806151    0.369108   -0.843748    0.966868   \n",
       "1    1.134896    1.232907    1.295312   -0.253926   -0.528711    0.502124   \n",
       "2    0.680959   -0.023550    0.932216    0.109495    0.500366    0.956182   \n",
       "3   -0.062296    0.583408    1.588965    0.412651   -1.891714   -0.575163   \n",
       "4   -0.296422   -0.755737   -0.489769    0.516726   -4.807225    1.215506   \n",
       "\n",
       "   Feature 25  Target  \n",
       "0   -0.547149       2  \n",
       "1    0.896065       1  \n",
       "2   -2.268742       0  \n",
       "3    0.786847       0  \n",
       "4    0.799321       1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = make_classification_dataframe(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_clusters_per_class=N_CLUSTERS_PER_CLASS, feature_name_prefix=FEATURE_NAME_PREFIX, target_name=TARGET_NAME, random_state=RANDOM_STATE)\n",
    "df_data.head()\n",
    "#df_data_train, df_data_val = train_test_split(df_data, test_size=0.2, random_state=RANDOM_STATE)\n",
    "#df_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array, target_type : type = int) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "    predicted_proba = np.array([])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "        predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X))\n",
    "\n",
    "    return actual_classes.astype(target_type), predicted_classes.astype(target_type), predicted_proba.reshape(X.shape[0], len(np.unique(y))) # Reshape to the number of rows in the source features and the number of unique classes that appear in the target. For example 10,000 data points with y = 0 or 1 will have produced an array (20000,) in shape that needs to be reshaped to (10000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "xg = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "cb = CatBoostClassifier(silent=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop([TARGET_NAME], axis=1)\n",
    "y = df_data[TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 248 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, lr_predicted, lr_predicted_proba = cross_val_predict(lr, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, rf_predicted, rf_predicted_proba = cross_val_predict(rf, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, xg_predicted, xg_predicted_proba = cross_val_predict(xg, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, cb_predicted, cb_predicted_proba = cross_val_predict(cb, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(predicted_probas : np.array) -> np.array:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            predicted_probas (np.array): [description]\n",
    "\n",
    "        Returns:\n",
    "            np.array: [description]\n",
    "        \"\"\"\n",
    "    \n",
    "    no_voters = predicted_probas.shape[0]\n",
    "    no_rows = predicted_probas.shape[1]\n",
    "    no_cols = predicted_probas.shape[2]\n",
    "    \n",
    "    sv_predicted_proba = np.empty(shape=(no_rows, no_cols))\n",
    "    sv_predicted_proba.fill(0)\n",
    "    \n",
    "    for i in range(0, no_cols - 1):\n",
    "        for j in range(0, no_voters):\n",
    "            sv_predicted_proba[:, i] += predicted_probas[j][:, i]\n",
    "        sv_predicted_proba[:, i] /= no_voters\n",
    "    \n",
    "    sv_predicted_proba[:,-1] = 1 - sv_predicted_proba.sum(axis=1)\n",
    "    sv_predicted = sv_predicted_proba.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    return sv_predicted_proba, sv_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_voting(predictions : np.array) -> np.array:\n",
    "    return [mode(v) for v in np.vstack(predictions).T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_predicted_proba, sv_predicted = soft_voting(np.array([rf_predicted_proba, xg_predicted_proba, cb_predicted_proba]))\n",
    "hv_predicted = hard_voting(np.array([rf_predicted, xg_predicted, cb_predicted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.6821\n",
      "Accuracy of Random Forest: 0.8742\n",
      "Accuracy of XG Boost: 0.8838\n",
      "Accuracy of Cat Boost: 0.8864\n",
      "Accuracy of Soft Voting: 0.8889\n",
      "Accuracy of Hard Voting: 0.8876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Logistic Regression: {accuracy_score(actual, lr_predicted)}\")\n",
    "print(f\"Accuracy of Random Forest: {accuracy_score(actual, rf_predicted)}\")\n",
    "print(f\"Accuracy of XG Boost: {accuracy_score(actual, xg_predicted)}\")\n",
    "print(f\"Accuracy of Cat Boost: {accuracy_score(actual, cb_predicted)}\")\n",
    "print(f\"Accuracy of Soft Voting: {accuracy_score(actual, sv_predicted)}\")\n",
    "print(f\"Accuracy of Hard Voting: {accuracy_score(actual, hv_predicted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html?highlight=roc_curve#sklearn.metrics.roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GHARRI~1\\AppData\\Local\\Temp/ipykernel_28220/1465685089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_predicted_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m--> 775\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(actual, lr_predicted_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GHARRI~1\\AppData\\Local\\Temp/ipykernel_28220/1956006219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_predicted_proba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[1;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \"\"\"\n\u001b[1;32m--> 675\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[0m\u001b[0;32m    676\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m                                              sample_weight=sample_weight)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(actual, lr_predicted_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
