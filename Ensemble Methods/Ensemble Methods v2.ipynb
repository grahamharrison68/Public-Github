{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE : int = 42\n",
    "N_SAMPLES : int = 10000\n",
    "N_FEATURES : int = 25\n",
    "N_CLASSES : int = 3\n",
    "N_CLUSTERS_PER_CLASS : int = 2\n",
    "    \n",
    "FEATURE_NAME_PREFIX : str = \"Feature\"\n",
    "TARGET_NAME : str = \"Target\"\n",
    "    \n",
    "N_SPLITS : int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_informative = N_CLASSES * N_CLUSTERS_PER_CLASS\n",
    "X, y = make_classification(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_informative=n_informative, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_dataframe(n_samples : int = 10000, n_features : int = 25, n_classes : int = 2, n_clusters_per_class : int = 2, feature_name_prefix : str = \"Feature\", target_name : str = \"Target\", random_state : int = 42) -> pd.DataFrame:\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative = n_classes * n_clusters_per_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    feature_names = [feature_name_prefix + \" \" + str(v) for v in np.arange(1, N_FEATURES+1)]\n",
    "    return pd.concat([pd.DataFrame(X, columns=feature_names), pd.DataFrame(y, columns=[target_name])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 17</th>\n",
       "      <th>Feature 18</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature 24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>-2.025205</td>\n",
       "      <td>-0.089634</td>\n",
       "      <td>-2.833473</td>\n",
       "      <td>0.315723</td>\n",
       "      <td>-0.254786</td>\n",
       "      <td>-1.873841</td>\n",
       "      <td>-1.082022</td>\n",
       "      <td>0.375549</td>\n",
       "      <td>-1.766212</td>\n",
       "      <td>-0.635775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450156</td>\n",
       "      <td>0.127255</td>\n",
       "      <td>0.964195</td>\n",
       "      <td>-0.570250</td>\n",
       "      <td>-1.121593</td>\n",
       "      <td>-0.859178</td>\n",
       "      <td>-0.390989</td>\n",
       "      <td>-1.916870</td>\n",
       "      <td>-2.367061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>-2.989839</td>\n",
       "      <td>-1.155186</td>\n",
       "      <td>-0.239581</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.410022</td>\n",
       "      <td>-0.348290</td>\n",
       "      <td>-0.758383</td>\n",
       "      <td>1.274005</td>\n",
       "      <td>0.306502</td>\n",
       "      <td>0.080855</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.913510</td>\n",
       "      <td>0.232358</td>\n",
       "      <td>0.684569</td>\n",
       "      <td>-0.683173</td>\n",
       "      <td>0.240665</td>\n",
       "      <td>1.259787</td>\n",
       "      <td>-1.251941</td>\n",
       "      <td>-0.059789</td>\n",
       "      <td>-0.655588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>-1.947663</td>\n",
       "      <td>0.520725</td>\n",
       "      <td>0.106356</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>1.670833</td>\n",
       "      <td>-0.674143</td>\n",
       "      <td>-0.678134</td>\n",
       "      <td>0.382928</td>\n",
       "      <td>-1.743136</td>\n",
       "      <td>0.115776</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.886197</td>\n",
       "      <td>0.989632</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>1.709442</td>\n",
       "      <td>-1.827470</td>\n",
       "      <td>2.403309</td>\n",
       "      <td>-0.809622</td>\n",
       "      <td>-1.238595</td>\n",
       "      <td>-0.869119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>-0.460435</td>\n",
       "      <td>1.280978</td>\n",
       "      <td>0.722993</td>\n",
       "      <td>0.344352</td>\n",
       "      <td>0.326570</td>\n",
       "      <td>-0.939769</td>\n",
       "      <td>0.130070</td>\n",
       "      <td>0.324532</td>\n",
       "      <td>-0.052836</td>\n",
       "      <td>0.087012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155966</td>\n",
       "      <td>-0.299105</td>\n",
       "      <td>0.262876</td>\n",
       "      <td>0.506887</td>\n",
       "      <td>0.535087</td>\n",
       "      <td>-0.920843</td>\n",
       "      <td>0.187716</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>-0.095456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>-0.053909</td>\n",
       "      <td>1.356961</td>\n",
       "      <td>-1.431071</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>2.191362</td>\n",
       "      <td>-0.511725</td>\n",
       "      <td>0.822338</td>\n",
       "      <td>-0.284092</td>\n",
       "      <td>-0.188173</td>\n",
       "      <td>0.436858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506829</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>0.582515</td>\n",
       "      <td>0.030940</td>\n",
       "      <td>-0.239184</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.864230</td>\n",
       "      <td>-2.424158</td>\n",
       "      <td>0.160253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "9254  -2.025205  -0.089634  -2.833473   0.315723  -0.254786  -1.873841   \n",
       "1561  -2.989839  -1.155186  -0.239581   0.043799   0.410022  -0.348290   \n",
       "1670  -1.947663   0.520725   0.106356   0.019951   1.670833  -0.674143   \n",
       "6087  -0.460435   1.280978   0.722993   0.344352   0.326570  -0.939769   \n",
       "6669  -0.053909   1.356961  -1.431071   0.039278   2.191362  -0.511725   \n",
       "\n",
       "      Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 17  \\\n",
       "9254  -1.082022   0.375549  -1.766212   -0.635775  ...    0.450156   \n",
       "1561  -0.758383   1.274005   0.306502    0.080855  ...   -1.913510   \n",
       "1670  -0.678134   0.382928  -1.743136    0.115776  ...   -1.886197   \n",
       "6087   0.130070   0.324532  -0.052836    0.087012  ...   -0.155966   \n",
       "6669   0.822338  -0.284092  -0.188173    0.436858  ...    0.506829   \n",
       "\n",
       "      Feature 18  Feature 19  Feature 20  Feature 21  Feature 22  Feature 23  \\\n",
       "9254    0.127255    0.964195   -0.570250   -1.121593   -0.859178   -0.390989   \n",
       "1561    0.232358    0.684569   -0.683173    0.240665    1.259787   -1.251941   \n",
       "1670    0.989632    0.165237    1.709442   -1.827470    2.403309   -0.809622   \n",
       "6087   -0.299105    0.262876    0.506887    0.535087   -0.920843    0.187716   \n",
       "6669   -0.175423    0.582515    0.030940   -0.239184    0.015029    0.864230   \n",
       "\n",
       "      Feature 24  Feature 25  Target  \n",
       "9254   -1.916870   -2.367061       0  \n",
       "1561   -0.059789   -0.655588       0  \n",
       "1670   -1.238595   -0.869119       0  \n",
       "6087    0.519180   -0.095456       0  \n",
       "6669   -2.424158    0.160253       0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = make_classification_dataframe(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_clusters_per_class=N_CLUSTERS_PER_CLASS, feature_name_prefix=FEATURE_NAME_PREFIX, target_name=TARGET_NAME, random_state=RANDOM_STATE)\n",
    "\n",
    "df_data_train, df_data_val = train_test_split(df_data, test_size=0.2, random_state=RANDOM_STATE)\n",
    "df_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array, target_type : type = int) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "    predicted_proba = np.array([])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "        predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X))\n",
    "\n",
    "    return actual_classes.astype(target_type), predicted_classes.astype(target_type), predicted_proba.reshape(X.shape[0], len(np.unique(y))) # Reshape to the number of rows in the source features and the number of unique classes that appear in the target. For example 10,000 data points with y = 0 or 1 will have produced an array (20000,) in shape that needs to be reshaped to (10000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "xg = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data_train.drop([TARGET_NAME], axis=1)\n",
    "y = df_data_train[TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, lr_predicted, lr_predicted_proba = cross_val_predict(lr, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, rf_predicted, rf_predicted_proba = cross_val_predict(rf, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, xg_predicted, xg_predicted_proba = cross_val_predict(xg, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(predicted_probas : np.array) -> np.array:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            predicted_probas (np.array): [description]\n",
    "\n",
    "        Returns:\n",
    "            np.array: [description]\n",
    "        \"\"\"\n",
    "    \n",
    "    no_voters = predicted_probas.shape[0]\n",
    "    no_rows = predicted_probas.shape[1]\n",
    "    no_cols = predicted_probas.shape[2]\n",
    "    \n",
    "    sv_predicted_proba = np.empty(shape=(no_rows, no_cols))\n",
    "    sv_predicted_proba.fill(0)\n",
    "    \n",
    "    for i in range(0, no_cols - 1):\n",
    "        for j in range(0, no_voters):\n",
    "            sv_predicted_proba[:, i] += predicted_probas[j][:, i]\n",
    "        sv_predicted_proba[:, i] /= no_voters\n",
    "    \n",
    "    sv_predicted_proba[:,-1] = 1 - sv_predicted_proba.sum(axis=1)\n",
    "    sv_predicted = sv_predicted_proba.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    return sv_predicted_proba, sv_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_voting(predictions : np.array) -> np.array:\n",
    "    return [mode(v) for v in np.vstack(predictions).T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_predicted_proba, sv_predicted = soft_voting(np.array([lr_predicted_proba, rf_predicted_proba, xg_predicted_proba]))\n",
    "hv_predicted = hard_voting(np.array([lr_predicted, rf_predicted, xg_predicted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.681125\n",
      "Accuracy of Random Forest: 0.864625\n",
      "Accuracy of XG Boost: 0.8745\n",
      "Accuracy of Soft Voting: 0.8655\n",
      "Accuracy of Hard Voting: 0.862\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Logistic Regression: {accuracy_score(actual, lr_predicted)}\")\n",
    "print(f\"Accuracy of Random Forest: {accuracy_score(actual, rf_predicted)}\")\n",
    "print(f\"Accuracy of XG Boost: {accuracy_score(actual, xg_predicted)}\")\n",
    "print(f\"Accuracy of Soft Voting: {accuracy_score(actual, sv_predicted)}\")\n",
    "print(f\"Accuracy of Hard Voting: {accuracy_score(actual, hv_predicted)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
