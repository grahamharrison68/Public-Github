{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/saurabhshahane/voting-classifier/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE : int = 42\n",
    "N_SAMPLES : int = 10000\n",
    "N_FEATURES : int = 25\n",
    "N_CLASSES : int = 3\n",
    "N_CLUSTERS_PER_CLASS : int = 3\n",
    "    \n",
    "FEATURE_NAME_PREFIX : str = \"Feature\"\n",
    "TARGET_NAME : str = \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_dataframe(n_samples : int = 10000, n_features : int = 25, n_classes : int = 2, n_clusters_per_class : int = 2, feature_name_prefix : str = \"Feature\", target_name : str = \"Target\", random_state : int = 42) -> pd.DataFrame:\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative = n_classes * n_clusters_per_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    feature_names = [feature_name_prefix + \" \" + str(v) for v in np.arange(1, N_FEATURES+1)]\n",
    "    return pd.concat([pd.DataFrame(X, columns=feature_names), pd.DataFrame(y, columns=[target_name])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 17</th>\n",
       "      <th>Feature 18</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature 24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.602070</td>\n",
       "      <td>-0.074587</td>\n",
       "      <td>1.002719</td>\n",
       "      <td>-1.001478</td>\n",
       "      <td>1.447140</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>-0.200570</td>\n",
       "      <td>0.646371</td>\n",
       "      <td>2.696937</td>\n",
       "      <td>-0.470317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961013</td>\n",
       "      <td>1.288696</td>\n",
       "      <td>3.254023</td>\n",
       "      <td>-1.654725</td>\n",
       "      <td>-4.036566</td>\n",
       "      <td>-0.664342</td>\n",
       "      <td>0.672532</td>\n",
       "      <td>1.011852</td>\n",
       "      <td>1.195234</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.904959</td>\n",
       "      <td>1.227717</td>\n",
       "      <td>-2.337397</td>\n",
       "      <td>-2.334397</td>\n",
       "      <td>0.862484</td>\n",
       "      <td>1.415096</td>\n",
       "      <td>1.214655</td>\n",
       "      <td>-0.462356</td>\n",
       "      <td>1.762339</td>\n",
       "      <td>1.465091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494576</td>\n",
       "      <td>-0.175983</td>\n",
       "      <td>-2.093386</td>\n",
       "      <td>1.014129</td>\n",
       "      <td>-0.014273</td>\n",
       "      <td>1.469496</td>\n",
       "      <td>0.566356</td>\n",
       "      <td>2.050482</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.246662</td>\n",
       "      <td>0.446997</td>\n",
       "      <td>0.242862</td>\n",
       "      <td>1.033087</td>\n",
       "      <td>-0.385963</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>2.084988</td>\n",
       "      <td>-2.308492</td>\n",
       "      <td>-1.545419</td>\n",
       "      <td>-1.367411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743195</td>\n",
       "      <td>-0.215827</td>\n",
       "      <td>-1.580021</td>\n",
       "      <td>3.148203</td>\n",
       "      <td>-1.088466</td>\n",
       "      <td>0.411244</td>\n",
       "      <td>-0.252259</td>\n",
       "      <td>-0.656534</td>\n",
       "      <td>-0.663363</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.104921</td>\n",
       "      <td>-0.047367</td>\n",
       "      <td>-4.663056</td>\n",
       "      <td>-1.609434</td>\n",
       "      <td>2.703973</td>\n",
       "      <td>-1.841072</td>\n",
       "      <td>-2.726065</td>\n",
       "      <td>6.055944</td>\n",
       "      <td>-0.176138</td>\n",
       "      <td>-1.320823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.146603</td>\n",
       "      <td>-1.079501</td>\n",
       "      <td>-0.155818</td>\n",
       "      <td>-3.836376</td>\n",
       "      <td>2.212267</td>\n",
       "      <td>-0.780577</td>\n",
       "      <td>0.186297</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>-0.302452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.669653</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.380804</td>\n",
       "      <td>0.808218</td>\n",
       "      <td>-1.521313</td>\n",
       "      <td>1.236502</td>\n",
       "      <td>0.237053</td>\n",
       "      <td>-1.589812</td>\n",
       "      <td>0.339948</td>\n",
       "      <td>0.364597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>0.638280</td>\n",
       "      <td>0.641545</td>\n",
       "      <td>2.059628</td>\n",
       "      <td>3.622518</td>\n",
       "      <td>-0.581747</td>\n",
       "      <td>-0.504654</td>\n",
       "      <td>-0.902726</td>\n",
       "      <td>-1.089139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0   2.602070  -0.074587   1.002719  -1.001478   1.447140   0.212351   \n",
       "1  -3.904959   1.227717  -2.337397  -2.334397   0.862484   1.415096   \n",
       "2   3.246662   0.446997   0.242862   1.033087  -0.385963   0.262805   \n",
       "3  -8.104921  -0.047367  -4.663056  -1.609434   2.703973  -1.841072   \n",
       "4   1.669653   0.352665  -0.380804   0.808218  -1.521313   1.236502   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 17  Feature 18  \\\n",
       "0  -0.200570   0.646371   2.696937   -0.470317  ...    0.961013    1.288696   \n",
       "1   1.214655  -0.462356   1.762339    1.465091  ...   -0.494576   -0.175983   \n",
       "2   2.084988  -2.308492  -1.545419   -1.367411  ...    0.743195   -0.215827   \n",
       "3  -2.726065   6.055944  -0.176138   -1.320823  ...    1.146603   -1.079501   \n",
       "4   0.237053  -1.589812   0.339948    0.364597  ...   -0.019907    0.638280   \n",
       "\n",
       "   Feature 19  Feature 20  Feature 21  Feature 22  Feature 23  Feature 24  \\\n",
       "0    3.254023   -1.654725   -4.036566   -0.664342    0.672532    1.011852   \n",
       "1   -2.093386    1.014129   -0.014273    1.469496    0.566356    2.050482   \n",
       "2   -1.580021    3.148203   -1.088466    0.411244   -0.252259   -0.656534   \n",
       "3   -0.155818   -3.836376    2.212267   -0.780577    0.186297    0.018554   \n",
       "4    0.641545    2.059628    3.622518   -0.581747   -0.504654   -0.902726   \n",
       "\n",
       "   Feature 25  Target  \n",
       "0    1.195234       2  \n",
       "1   -0.038749       0  \n",
       "2   -0.663363       2  \n",
       "3   -0.302452       1  \n",
       "4   -1.089139       1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = make_classification_dataframe(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_clusters_per_class=N_CLUSTERS_PER_CLASS, feature_name_prefix=FEATURE_NAME_PREFIX, target_name=TARGET_NAME, random_state=RANDOM_STATE)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_data.drop([TARGET_NAME], axis=1))\n",
    "y = np.array(df_data[TARGET_NAME], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [['Neural Network :', MLPClassifier(max_iter = 1000, random_state=RANDOM_STATE)],\n",
    "               ['LogisticRegression :', LogisticRegression(max_iter = 1000, random_state=RANDOM_STATE)],\n",
    "               ['ExtraTreesClassifier :', ExtraTreesClassifier(random_state=RANDOM_STATE)],\n",
    "               ['DecisionTree :',DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "               ['RandomForest :',RandomForestClassifier(random_state=RANDOM_STATE)], \n",
    "               ['Naive Bayes :', GaussianNB()],\n",
    "               ['KNeighbours :', KNeighborsClassifier()],\n",
    "               ['SVM :', SVC(probability=True, random_state=RANDOM_STATE)],\n",
    "               ['AdaBoostClassifier :', AdaBoostClassifier(random_state=RANDOM_STATE)],\n",
    "               ['GradientBoostingClassifier: ', GradientBoostingClassifier(random_state=RANDOM_STATE)],\n",
    "               ['XGB :', XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=RANDOM_STATE)],\n",
    "#               ['CatBoost :', CatBoostClassifier(logging_level='Silent, random_state=RANDOM_STATE')]\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network : 0.8993333333333333\n",
      "LogisticRegression : 0.7326666666666667\n",
      "ExtraTreesClassifier : 0.8933333333333333\n",
      "DecisionTree : 0.746\n",
      "RandomForest : 0.879\n",
      "Naive Bayes : 0.6966666666666667\n",
      "KNeighbours : 0.8773333333333333\n",
      "SVM : 0.9053333333333333\n",
      "AdaBoostClassifier : 0.689\n",
      "GradientBoostingClassifier:  0.8383333333333334\n",
      "XGB : 0.8886666666666667\n"
     ]
    }
   ],
   "source": [
    "for name,classifier in classifiers:\n",
    "    classifier = classifier\n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(name, accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft 0.9033333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       991\n",
      "           1       0.91      0.88      0.89       980\n",
      "           2       0.91      0.91      0.91      1029\n",
      "\n",
      "    accuracy                           0.90      3000\n",
      "   macro avg       0.90      0.90      0.90      3000\n",
      "weighted avg       0.90      0.90      0.90      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=classifiers, voting='soft')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"soft\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       991\n",
      "           1       0.89      0.86      0.88       980\n",
      "           2       0.91      0.89      0.90      1029\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.89      0.89      0.89      3000\n",
      "weighted avg       0.89      0.89      0.89      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"hard\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [['RandomForest :',RandomForestClassifier(random_state=RANDOM_STATE)], \n",
    "               ['XGB :', XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=RANDOM_STATE)],\n",
    "               ['CatBoost :', CatBoostClassifier(logging_level='Silent', random_state=RANDOM_STATE)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHarrison\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3000,1) into shape (3000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GHARRI~1\\AppData\\Local\\Temp/ipykernel_21800/3515793377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0meclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0meclf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hard\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m             maj = np.apply_along_axis(\n\u001b[0;32m    287\u001b[0m                 lambda x: np.argmax(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3000,1) into shape (3000)"
     ]
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "eclf1.fit(X_train, y_train)\n",
    "predictions = eclf1.predict(X_test)\n",
    "print(\"hard\", accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``CatBoost`` algorithm cannot be used in a hard voting classifier when there are more than 2 classes. If this is tried it throws an error - ``ValueError: could not broadcast input array from shape (3000,1) into shape (3000)``"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
