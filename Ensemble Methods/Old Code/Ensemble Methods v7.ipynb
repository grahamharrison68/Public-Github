{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from statistics import mode\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE : int = 42\n",
    "N_SAMPLES : int = 10000\n",
    "N_FEATURES : int = 25\n",
    "N_CLASSES : int = 3\n",
    "N_CLUSTERS_PER_CLASS : int = 2\n",
    "    \n",
    "FEATURE_NAME_PREFIX : str = \"Feature\"\n",
    "TARGET_NAME : str = \"Target\"\n",
    "    \n",
    "N_SPLITS : int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = make_classification(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_informative=(N_CLASSES * N_CLUSTERS_PER_CLASS), random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_dataframe(n_samples : int = 10000, n_features : int = 25, n_classes : int = 2, n_clusters_per_class : int = 2, feature_name_prefix : str = \"Feature\", target_name : str = \"Target\", random_state : int = 42) -> pd.DataFrame:\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative = n_classes * n_clusters_per_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    feature_names = [feature_name_prefix + \" \" + str(v) for v in np.arange(1, N_FEATURES+1)]\n",
    "    return pd.concat([pd.DataFrame(X, columns=feature_names), pd.DataFrame(y, columns=[target_name])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 17</th>\n",
       "      <th>Feature 18</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature 24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.131637</td>\n",
       "      <td>2.281512</td>\n",
       "      <td>0.468810</td>\n",
       "      <td>0.707735</td>\n",
       "      <td>1.628051</td>\n",
       "      <td>0.622273</td>\n",
       "      <td>-0.434003</td>\n",
       "      <td>-0.992722</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>-1.764985</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.673779</td>\n",
       "      <td>0.276305</td>\n",
       "      <td>-1.685462</td>\n",
       "      <td>-0.801336</td>\n",
       "      <td>0.806151</td>\n",
       "      <td>0.369108</td>\n",
       "      <td>-0.843748</td>\n",
       "      <td>0.966868</td>\n",
       "      <td>-0.547149</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.231544</td>\n",
       "      <td>-1.580880</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>-0.343771</td>\n",
       "      <td>0.498176</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.859592</td>\n",
       "      <td>-0.666477</td>\n",
       "      <td>-0.832989</td>\n",
       "      <td>-0.287655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341136</td>\n",
       "      <td>1.116596</td>\n",
       "      <td>1.134896</td>\n",
       "      <td>1.232907</td>\n",
       "      <td>1.295312</td>\n",
       "      <td>-0.253926</td>\n",
       "      <td>-0.528711</td>\n",
       "      <td>0.502124</td>\n",
       "      <td>0.896065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.301585</td>\n",
       "      <td>-1.922563</td>\n",
       "      <td>-0.623878</td>\n",
       "      <td>-0.740534</td>\n",
       "      <td>-0.723667</td>\n",
       "      <td>1.484827</td>\n",
       "      <td>1.227018</td>\n",
       "      <td>-0.050878</td>\n",
       "      <td>0.164059</td>\n",
       "      <td>0.301672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900290</td>\n",
       "      <td>0.682905</td>\n",
       "      <td>0.680959</td>\n",
       "      <td>-0.023550</td>\n",
       "      <td>0.932216</td>\n",
       "      <td>0.109495</td>\n",
       "      <td>0.500366</td>\n",
       "      <td>0.956182</td>\n",
       "      <td>-2.268742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.899385</td>\n",
       "      <td>0.991619</td>\n",
       "      <td>0.494529</td>\n",
       "      <td>-0.672954</td>\n",
       "      <td>0.421605</td>\n",
       "      <td>-0.271674</td>\n",
       "      <td>1.245351</td>\n",
       "      <td>0.146567</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>1.479558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285753</td>\n",
       "      <td>-1.446158</td>\n",
       "      <td>-0.062296</td>\n",
       "      <td>0.583408</td>\n",
       "      <td>1.588965</td>\n",
       "      <td>0.412651</td>\n",
       "      <td>-1.891714</td>\n",
       "      <td>-0.575163</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.026721</td>\n",
       "      <td>0.745777</td>\n",
       "      <td>0.188450</td>\n",
       "      <td>-0.794256</td>\n",
       "      <td>1.402570</td>\n",
       "      <td>1.057481</td>\n",
       "      <td>0.454773</td>\n",
       "      <td>-0.174391</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>-0.403872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959229</td>\n",
       "      <td>-1.964891</td>\n",
       "      <td>-0.296422</td>\n",
       "      <td>-0.755737</td>\n",
       "      <td>-0.489769</td>\n",
       "      <td>0.516726</td>\n",
       "      <td>-4.807225</td>\n",
       "      <td>1.215506</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0  -0.131637   2.281512   0.468810   0.707735   1.628051   0.622273   \n",
       "1  -1.231544  -1.580880   0.684543  -0.343771   0.498176  -0.008396   \n",
       "2  -1.301585  -1.922563  -0.623878  -0.740534  -0.723667   1.484827   \n",
       "3  -0.899385   0.991619   0.494529  -0.672954   0.421605  -0.271674   \n",
       "4  -3.026721   0.745777   0.188450  -0.794256   1.402570   1.057481   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 17  Feature 18  \\\n",
       "0  -0.434003  -0.992722   0.053795   -1.764985  ...   -1.673779    0.276305   \n",
       "1  -0.859592  -0.666477  -0.832989   -0.287655  ...    0.341136    1.116596   \n",
       "2   1.227018  -0.050878   0.164059    0.301672  ...   -0.900290    0.682905   \n",
       "3   1.245351   0.146567   0.389313    1.479558  ...   -0.285753   -1.446158   \n",
       "4   0.454773  -0.174391   0.951417   -0.403872  ...    0.959229   -1.964891   \n",
       "\n",
       "   Feature 19  Feature 20  Feature 21  Feature 22  Feature 23  Feature 24  \\\n",
       "0   -1.685462   -0.801336    0.806151    0.369108   -0.843748    0.966868   \n",
       "1    1.134896    1.232907    1.295312   -0.253926   -0.528711    0.502124   \n",
       "2    0.680959   -0.023550    0.932216    0.109495    0.500366    0.956182   \n",
       "3   -0.062296    0.583408    1.588965    0.412651   -1.891714   -0.575163   \n",
       "4   -0.296422   -0.755737   -0.489769    0.516726   -4.807225    1.215506   \n",
       "\n",
       "   Feature 25  Target  \n",
       "0   -0.547149       2  \n",
       "1    0.896065       1  \n",
       "2   -2.268742       0  \n",
       "3    0.786847       0  \n",
       "4    0.799321       1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = make_classification_dataframe(n_samples=N_SAMPLES, n_features=N_FEATURES, n_classes=N_CLASSES, n_clusters_per_class=N_CLUSTERS_PER_CLASS, feature_name_prefix=FEATURE_NAME_PREFIX, target_name=TARGET_NAME, random_state=RANDOM_STATE)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_old(model, kfold : KFold, X : np.array, y : np.array, target_type : type = int) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_rows = X.shape[0]\n",
    "    no_classifications = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "    predicted_proba = np.array([])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X))\n",
    "            print(predicted_proba.shape)\n",
    "            print(model_.predict_proba(test_X).shape)\n",
    "        except AttributeError:\n",
    "            # When the model is a VotingClassifier with voting=\"hard\" the following error is generated - AttributeError: predict_proba is not available when voting='hard'. In this instance the predicted_probas array is filled with float zeroes with the same number of rows as the source data set and a number of columns equal to the number of classes in the classification\n",
    "            predicted_proba = np.zeros((no_rows, no_classifications), dtype=float)\n",
    "\n",
    "    return actual_classes.astype(target_type), predicted_classes.astype(target_type), predicted_proba.reshape(no_rows, no_classifications) # Reshape to the number of rows in the source features and the number of unique classes that appear in the target. For example 10,000 data points with y = 0 or 1 will have produced an array (20000,) in shape that needs to be reshaped to (10000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, kfold : KFold, X : np.array, y : np.array, target_type : type = int) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    #no_rows = X.shape[0]\n",
    "    no_classifications = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.array([])\n",
    "    predicted_classes = np.array([])\n",
    "    #predicted_proba = np.array([])\n",
    "    predicted_proba = np.empty([0, no_classifications])\n",
    "\n",
    "    splits = kfold.split(X)\n",
    "    \n",
    "    for train_ndx, test_ndx in splits:\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "            print(predicted_proba.shape)\n",
    "            print(model_.predict_proba(test_X).shape)\n",
    "        except AttributeError:\n",
    "            # When the model is a VotingClassifier with voting=\"hard\" the following error is generated - AttributeError: predict_proba is not available when voting='hard'. In this instance the predicted_probas array is filled with float zeroes with the same number of rows as the source data set and a number of columns equal to the number of classes in the classification\n",
    "            #predicted_proba = np.zeros((no_rows, no_classifications), dtype=float)\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros_like(test_X, dtype=float))\n",
    "\n",
    "    #return actual_classes.astype(target_type), predicted_classes.astype(target_type), predicted_proba.reshape(no_rows, no_classifications) # Reshape to the number of rows in the source features and the number of unique classes that appear in the target. For example 10,000 data points with y = 0 or 1 will have produced an array (20000,) in shape that needs to be reshaped to (10000,2)\n",
    "    return actual_classes.astype(target_type), predicted_classes.astype(target_type), predicted_proba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predicted_proba.shape\n",
    "GH_ = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 3), (2000, 3), (2000, 3))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = rf_predicted_proba[0:2000]\n",
    "test2 = rf_predicted_proba[2000:4000]\n",
    "test3 = rf_predicted_proba[4000:6000]\n",
    "\n",
    "test1.shape, test2.shape, test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GH = np.empty([0, 3])\n",
    "GH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GH = np.append(GH, test1, axis=0)\n",
    "GH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GH = np.append(GH, test2, axis=0)\n",
    "GH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GH = np.empty([0,2])\n",
    "#GH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_proba = np.array([0,2])\n",
    "#predicted_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "xg = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "#cb = CatBoostClassifier(silent=True, random_state=RANDOM_STATE)\n",
    "xt = ExtraTreesClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.drop([TARGET_NAME], axis=1)\n",
    "y = df_data[TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n",
      "(2000, 3)\n",
      "(4000, 3)\n",
      "(2000, 3)\n",
      "(6000, 3)\n",
      "(2000, 3)\n",
      "(8000, 3)\n",
      "(2000, 3)\n",
      "(10000, 3)\n",
      "(2000, 3)\n",
      "Wall time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, lr_predicted, lr_predicted_proba = cross_val_predict(lr, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44910829, 0.24542133, 0.30547038],\n",
       "       [0.3697233 , 0.34403066, 0.28624605],\n",
       "       [0.26560338, 0.43007386, 0.30432276],\n",
       "       ...,\n",
       "       [0.38909524, 0.26281518, 0.34808958],\n",
       "       [0.15035778, 0.03440465, 0.81523757],\n",
       "       [0.02246867, 0.84043645, 0.13709489]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44910829, 0.24542133, 0.30547038],\n",
       "       [0.3697233 , 0.34403066, 0.28624605],\n",
       "       [0.26560338, 0.43007386, 0.30432276],\n",
       "       ...,\n",
       "       [0.38909524, 0.26281518, 0.34808958],\n",
       "       [0.15035778, 0.03440465, 0.81523757],\n",
       "       [0.02246867, 0.84043645, 0.13709489]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predicted_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n",
      "(2000, 3)\n",
      "(4000, 3)\n",
      "(2000, 3)\n",
      "(6000, 3)\n",
      "(2000, 3)\n",
      "(8000, 3)\n",
      "(2000, 3)\n",
      "(10000, 3)\n",
      "(2000, 3)\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, rf_predicted, rf_predicted_proba = cross_val_predict(rf, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "(2000, 3)\n",
      "(12000,)\n",
      "(2000, 3)\n",
      "(18000,)\n",
      "(2000, 3)\n",
      "(24000,)\n",
      "(2000, 3)\n",
      "(30000,)\n",
      "(2000, 3)\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, xg_predicted, xg_predicted_proba = cross_val_predict(xg, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "(2000, 3)\n",
      "(12000,)\n",
      "(2000, 3)\n",
      "(18000,)\n",
      "(2000, 3)\n",
      "(24000,)\n",
      "(2000, 3)\n",
      "(30000,)\n",
      "(2000, 3)\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, xt_predicted, xt_predicted_proba = cross_val_predict(xt, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(predicted_probas : np.array) -> np.array:\n",
    "\n",
    "    no_voters = predicted_probas.shape[0]\n",
    "    no_rows = predicted_probas.shape[1]\n",
    "    no_cols = predicted_probas.shape[2]\n",
    "    \n",
    "    sv_predicted_proba = np.empty(shape=(no_rows, no_cols))\n",
    "    sv_predicted_proba.fill(0)\n",
    "    \n",
    "    for i in range(0, no_cols - 1):\n",
    "        for j in range(0, no_voters):\n",
    "            sv_predicted_proba[:, i] += predicted_probas[j][:, i]\n",
    "        sv_predicted_proba[:, i] /= no_voters\n",
    "    \n",
    "    sv_predicted_proba[:,-1] = 1 - sv_predicted_proba.sum(axis=1)\n",
    "    sv_predicted = sv_predicted_proba.argmax(axis=1)\n",
    "\n",
    "    \n",
    "    return sv_predicted_proba, sv_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_voting(predictions : np.array) -> np.array:\n",
    "    return [mode(v) for v in predictions.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to understand the ``predicted_probas`` array by taking a look at its shape ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10000, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probas = np.array([lr_predicted_proba, rf_predicted_proba, xg_predicted_proba, xt_predicted_proba])\n",
    "predicted_probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a 3 dimensional array. The first dimension is the number of classification algorithms, the second the number of rows in the data that predictions are held for and the third is the number of classes. Remember this is not a binary classification, we set the number of classes to 3 when the data was generated.\n",
    "\n",
    "This sets things up to set the 3 variables for the number of voters, rows and columns which is not strictly speaking necessary but it does make the subsequent code more readable ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10000 3\n"
     ]
    }
   ],
   "source": [
    "no_voters = predicted_probas.shape[0]\n",
    "no_rows = predicted_probas.shape[1]\n",
    "no_cols = predicted_probas.shape[2]\n",
    "\n",
    "print(no_voters, no_rows, no_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to remind ourselves what the ``predicted_proba`` property looks like for a scikit-learn classifier ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.02, 0.81],\n",
       "       [0.58, 0.07, 0.35],\n",
       "       [0.54, 0.1 , 0.36],\n",
       "       ...,\n",
       "       [0.46, 0.08, 0.46],\n",
       "       [0.15, 0.  , 0.85],\n",
       "       [0.01, 0.97, 0.02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest ``predicted_proba`` property contains an array with 10,000 rows and 3 columns. It has one row for each data point and one column for each of the classifications, remembering that this is not a binary classification, our classification can have 3 values ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3353\n",
       "1    3330\n",
       "2    3317\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[TARGET_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for the first row of data the Random Forest has predicted a 17% probability of the row belonging to class 0, a 2% probability of class 1 and an 81% probability of class 2. This means that the data in the first row is predicted as belonging to class 2 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing the code in the helpder function does is to create an empty array that is going to hold the result of the soft voting. This needs to have 10,000 rows (one for every data point) and three columns (one for the probability of the first class, one for the second and one for the third) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_predicted_proba = np.empty(shape=(no_rows, no_cols))\n",
    "sv_predicted_proba.fill(0)\n",
    "\n",
    "print(sv_predicted_proba.shape)\n",
    "sv_predicted_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next for the main iteration. It will iterate over all the columns except the last one. This seems a bit strange as we need a probability for all of the classifiers but hold on for a bit and we will come back to that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "print(*range(0, no_cols - 1)) # see https://stackoverflow.com/questions/18424899/print-range-of-numbers-on-same-line "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the whole iteration ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, no_cols - 1):\n",
    "    for j in range(0, no_voters):\n",
    "        sv_predicted_proba[:, i] += predicted_probas[j][:, i]\n",
    "    sv_predicted_proba[:, i] /= no_voters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are iterating over every column / classifier except the last one. For each column we are adding the predicted probability of each of our algorithms together and dividing by the number of algorithms. When the iteration completes, the result looks like this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25130534, 0.07156967, 0.        ],\n",
       "       [0.61069015, 0.13897641, 0.        ],\n",
       "       [0.44524877, 0.17840206, 0.        ],\n",
       "       ...,\n",
       "       [0.53029539, 0.11065982, 0.        ],\n",
       "       [0.10525607, 0.01649241, 0.        ],\n",
       "       [0.02081474, 0.93477913, 0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_predicted_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final column / classification is blank where as if we had iterated over all of the columns / classifiers it would have been populated. The problem is that had we done so the sum of each row would not always be exactly one due to rounding errors.\n",
    "\n",
    "Therefore, rather than using the iteration to set all three columns / classifiers an additional line of code sets the third one to be 1 minus the sum of the others ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_predicted_proba[:,-1] = 1 - sv_predicted_proba.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25130534, 0.07156967, 0.67712499],\n",
       "       [0.61069015, 0.13897641, 0.25033344],\n",
       "       [0.44524877, 0.17840206, 0.37634917],\n",
       "       ...,\n",
       "       [0.53029539, 0.11065982, 0.35904478],\n",
       "       [0.10525607, 0.01649241, 0.87825152],\n",
       "       [0.02081474, 0.93477913, 0.04440614]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_predicted_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! The ``sv_predicted_proba`` array contains a soft-voted version of the probabilities for each class based on the average of the ``predicted_probas`` property from each of the contributing algorithms,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still need to know the class prediction (i.e. for each row did the soft vote predict class 0, 1 or 2). Fortunately the wonderful ``argmax`` function in the ``numpy`` library enables to do this in a single line of code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_predicted = sv_predicted_proba.argmax(axis=1)\n",
    "sv_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``argmax`` function simply picks the index of the highest value in an array along the axis specified in the ``axis`` parameter, so it picks 2 for the first row, 0 for the second, zero for the third etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have hand crafted the predicted probabilities and the predicted classes using the soft voting algorithm and in the process of writing the code from scratch we have attained a full understanding of exactly how soft voting works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard voting is subtly different. Whereas soft voting averages the probability, hard voting picks the class that the majority of the algorithms voted for, for example ...\n",
    "\n",
    "- Class 2, Class 2, Class 0 = Class 2\n",
    "- Class 1, Class 1, Class 2 = Class 1\n",
    "- Class 0, Class 0, Class 0 = Class 0\n",
    "- Class 0, Class 1, Class 2 = Class 0 (actually, it would not matter which one is picked here as they have one vote each)\n",
    "\n",
    "The hard voting algorithm can be implemented in a single line of code using Python list comprehension and ``numpy`` array functions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([rf_predicted, xg_predicted, xt_predicted])\n",
    "\n",
    "hv_predicted = [mode(v) for v in predictions.T] # Single line of code to implement the hard voting algorithm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``predictions.T`` syntax just transposes the array of arrays so that instead of 3 rows and 10,000 columns it is 10,000 rowns and 3 columns ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, ..., 0, 2, 1],\n",
       "       [2, 0, 2, ..., 0, 2, 1],\n",
       "       [2, 0, 0, ..., 0, 2, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [0, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [2, 2, 2],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions.T.shape)\n",
    "predictions.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list comprehension then effectively takes each element (row) and applies ``statistics.mode`` to it, thereby selecting the classification that received the most votes from the algorithms ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hv_predicted) # Shows the result for the 1st 3 and last 3 rows as displayed in the previous code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a full understanding of the helpder functions and a deep understanding of how soft and hard voting works those helpder functions can be re-used to generate the results.\n",
    "\n",
    "Note that I included the Logistic Regression in the example code above to purposely create an array with shape 4, 10000, 3 to avoid confusion in the subsequent explanation.\n",
    "\n",
    "Through trial-and-error I found that the logistic regression has low accuracy for this dataset, hence I have excluded it in the final run to help illustrate the point that soft and hard voting genuinely does improve algorithm accuracy ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_predicted_proba, sv_predicted = soft_voting(np.array([rf_predicted_proba, xg_predicted_proba, xt_predicted_proba]))\n",
    "hv_predicted = hard_voting(np.array([rf_predicted, xg_predicted, xt_predicted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.6821\n",
      "Accuracy of Random Forest: 0.8742\n",
      "Accuracy of XG Boost: 0.8838\n",
      "Accuracy of Extra Random Trees: 0.8754\n",
      "Accuracy of Soft Voting: 0.8868\n",
      "Accuracy of Hard Voting: 0.881\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Logistic Regression: {accuracy_score(actual, lr_predicted)}\")\n",
    "print(f\"Accuracy of Random Forest: {accuracy_score(actual, rf_predicted)}\")\n",
    "print(f\"Accuracy of XG Boost: {accuracy_score(actual, xg_predicted)}\")\n",
    "print(f\"Accuracy of Extra Random Trees: {accuracy_score(actual, xt_predicted)}\")\n",
    "print(f\"Accuracy of Soft Voting: {accuracy_score(actual, sv_predicted)}\")\n",
    "print(f\"Accuracy of Hard Voting: {accuracy_score(actual, hv_predicted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with that understanding we can revert to using the implementations found in the scikit-learn library safe with the knowledge that we fully understand what they are doing and how they work ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "estimators=[('rf', rf), ('xg', xg), ('xt', xt)]\n",
    "\n",
    "vc_sv = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "vc_hv = VotingClassifier(estimators=estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "(2000, 3)\n",
      "(12000,)\n",
      "(2000, 3)\n",
      "(18000,)\n",
      "(2000, 3)\n",
      "(24000,)\n",
      "(2000, 3)\n",
      "(30000,)\n",
      "(2000, 3)\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, vc_sv_predicted, vc_sv_predicted_proba = cross_val_predict(vc_sv, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actual, vc_hv_predicted, _ = cross_val_predict(vc_hv, kfold, X.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/saurabhshahane/voting-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SciKit-Learn Soft Voting: 0.8868\n",
      "Accuracy of SciKit-Learn Hard Voting: 0.881\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of SciKit-Learn Soft Voting: {accuracy_score(actual, vc_sv_predicted)}\")\n",
    "print(f\"Accuracy of SciKit-Learn Hard Voting: {accuracy_score(actual, vc_hv_predicted)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
